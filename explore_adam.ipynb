{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7e26da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wrangle as w\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b54f3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = w.post_explore_wrangle_github_repositories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bef0260a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "      <th>cleaned_readme_contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>huggingface/transformers</td>\n",
       "      <td>Python</td>\n",
       "      <td>&lt;!---\\nCopyright 2020 The HuggingFace Team. Al...</td>\n",
       "      <td>copyright 2020 huggingface team right reserved...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apachecn/ailearning</td>\n",
       "      <td>Python</td>\n",
       "      <td>&lt;p align=\"center\"&gt;\\n    &lt;a href=\"https://www.a...</td>\n",
       "      <td>p aligncenter hrefhttpswwwapachecnorg img widt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>google-research/bert</td>\n",
       "      <td>Python</td>\n",
       "      <td># BERT\\n\\n**\\*\\*\\*\\*\\* New March 11th, 2020: S...</td>\n",
       "      <td>bert new march 11th 2020 smaller bert model re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hankcs/HanLP</td>\n",
       "      <td>Python</td>\n",
       "      <td>&lt;div align=\"center\"&gt;&lt;img src=\"https://file.han...</td>\n",
       "      <td>div aligncenterimg srchttps_link height100pxdi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>explosion/spaCy</td>\n",
       "      <td>Python</td>\n",
       "      <td>&lt;a href=\"https://explosion.ai\"&gt;&lt;img src=\"https...</td>\n",
       "      <td>hrefhttpsexplosionaiimg srchttps_link width125...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       repo language  \\\n",
       "0  huggingface/transformers   Python   \n",
       "1       apachecn/ailearning   Python   \n",
       "2      google-research/bert   Python   \n",
       "3              hankcs/HanLP   Python   \n",
       "4           explosion/spaCy   Python   \n",
       "\n",
       "                                     readme_contents  \\\n",
       "0  <!---\\nCopyright 2020 The HuggingFace Team. Al...   \n",
       "1  <p align=\"center\">\\n    <a href=\"https://www.a...   \n",
       "2  # BERT\\n\\n**\\*\\*\\*\\*\\* New March 11th, 2020: S...   \n",
       "3  <div align=\"center\"><img src=\"https://file.han...   \n",
       "4  <a href=\"https://explosion.ai\"><img src=\"https...   \n",
       "\n",
       "                             cleaned_readme_contents  \n",
       "0  copyright 2020 huggingface team right reserved...  \n",
       "1  p aligncenter hrefhttpswwwapachecnorg img widt...  \n",
       "2  bert new march 11th 2020 smaller bert model re...  \n",
       "3  div aligncenterimg srchttps_link height100pxdi...  \n",
       "4  hrefhttpsexplosionaiimg srchttps_link width125...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83c3fdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = w.train_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acfdd5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p align=\"center\">\\n    <a href=\"https://www.apachecn.org\">\\n        <img width=\"200\" src=\"docs/img/logo.jpg\">\\n    </a>\\n    <br >\\n    <a href=\"https://www.apachecn.org/\"><img src=\"https://img.shields.io/badge/%3E-HOME-green.svg\"></a>\\n    <a href=\"https://home.apachecn.org/about/\"><img src=\"https://img.shields.io/badge/%3E-ABOUT-green.svg\"></a>\\n    <a href=\"mailto:apache@163.com\"><img src=\"https://img.shields.io/badge/%3E-Email-green.svg\"></a>\\n</p>\\n\\n<h1 align=\"center\"><a href=\"https://github.com/apachecn/AiLearning\">AI learning</a></h1>\\n\\n> 协议：[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh)\\n> \\n> 一种新技术一旦开始流行，你要么坐上压路机，要么成为铺路石。——Stewart Brand\\n\\n* [在线阅读](https://ailearning.apachecn.org)\\n* [在线阅读（v1）](https://alv1.apachecn.org/)\\n* [QuantLearning](https://qlearn.apachecn.org/#/)\\n* [ApacheCN 中文翻译组 713436582](https://qm.qq.com/cgi-bin/qm/qr?k=5u_aAU-YlY3fH-m8meXTJzBEo2boQIUs&jump_from=webapi&authKey=CVZcReMt/vKdTXZBQ8ly+jWncXiSzzWOlrx5hybX5pSrKu6s0fvGX54+vHHlgYNt)\\n* [ApacheCN 学习资源](https://www.apachecn.org/)\\n* 注: 广告位合作(物美价廉)，请联系 <apachecn@163.com>\\n\\n# 路线图\\n\\n* 入门只看: 步骤 1 => 2 => 3，你可以当大牛！\\n* 中级补充 - 资料库: <https://github.com/apachecn/ai-roadmap>\\n\\n> 补充\\n\\n* 算法刷题: <https://www.ixigua.com/pseries/6822642486343631363/>\\n* 面试求职: <https://www.ixigua.com/pseries/6822563009391493636/>\\n* 机器学习实战: <https://www.ixigua.com/pseries/6822816341615968772/>\\n* NLP教学视频: <https://www.ixigua.com/pseries/6828241431295951373/>\\n* **AI常用函数说明**: <https://github.com/apachecn/AiLearning/tree/master/AI常用函数说明.md>\\n\\n## 1.机器学习 - 基础\\n\\n> 支持版本 \\n\\n| Version | Supported          |\\n| ------- | ------------------ |\\n| 3.6.x   | :x:                |\\n| 2.7.x   | :white_check_mark: |\\n\\n注意事项: \\n\\n- 机器学习实战: 仅仅只是学习，请使用 python 2.7.x 版本 （3.6.x 只是修改了部分）\\n\\n### 基本介绍\\n\\n* 资料来源: Machine Learning in Action(机器学习实战-个人笔记)\\n* 统一数据地址: <https://github.com/apachecn/data>\\n  * 百度云打包地址: <https://github.com/apachecn/data/issues/3>\\n* 书籍下载地址: <https://github.com/apachecn/data/tree/master/book>\\n* 机器学习下载地址: <https://github.com/apachecn/data/tree/master/机器学习>\\n* 深度学习数据地址: <https://github.com/apachecn/data/tree/master/深度学习>\\n* 推荐系统数据地址: <https://github.com/apachecn/data/tree/master/推荐系统>\\n* 视频网站: 优酷 ／bilibili / Acfun / 网易云课堂，可直接在线播放。（最下方有相应链接）\\n* -- 推荐 [红色石头](https://github.com/RedstoneWill): [台湾大学林轩田机器学习笔记](https://github.com/apachecn/ntu-hsuantienlin-ml)\\n* -- 推荐 [机器学习笔记](https://feisky.xyz/machine-learning): https://feisky.xyz/machine-learning\\n\\n### 学习文档\\n\\n| 模块 | 章节 | 类型 | 负责人(GitHub) | QQ |\\n| --- | --- | --- | --- | --- |\\n| 机器学习实战 | [第 1 章: 机器学习基础](/docs/ml/1.md) | 介绍 | [@毛红动](https://github.com/ElmaDavies) | 1306014226 |\\n| 机器学习实战 | [第 2 章: KNN 近邻算法](/docs/ml/2.md) | 分类 | [@尤永江](https://github.com/youyj521) | 279393323 |\\n| 机器学习实战 | [第 3 章: 决策树](/docs/ml/3.md) | 分类 | [@景涛](https://github.com/jingwangfei) | 844300439 |\\n| 机器学习实战 | [第 4 章: 朴素贝叶斯](/docs/ml/4.md) | 分类 | [@wnma3mz](https://github.com/wnma3mz)<br/>[@分析](https://github.com/kailian) | 1003324213<br/>244970749 |\\n| 机器学习实战 | [第 5 章: Logistic回归](/docs/ml/5.md) | 分类 | [@微光同尘](https://github.com/DataMonk2017) | 529925688 |\\n| 机器学习实战 | [第 6 章: SVM 支持向量机](/docs/ml/6.md) | 分类 | [@王德红](https://github.com/VPrincekin) | 934969547 |\\n| 网上组合内容 | [第 7 章: 集成方法（随机森林和 AdaBoost）](/docs/ml/7.md) | 分类 | [@片刻](https://github.com/jiangzhonglian) | 529815144 |\\n| 机器学习实战 | [第 8 章: 回归](/docs/ml/8.md) | 回归 | [@微光同尘](https://github.com/DataMonk2017) | 529925688 |\\n| 机器学习实战 | [第 9 章: 树回归](/docs/ml/9.md) | 回归 | [@微光同尘](https://github.com/DataMonk2017) | 529925688 |\\n| 机器学习实战 | [第 10 章: K-Means 聚类](/docs/ml/10.md) | 聚类 | [@徐昭清](https://github.com/xuzhaoqing) | 827106588 |\\n| 机器学习实战 | [第 11 章: 利用 Apriori 算法进行关联分析](/docs/ml/11.md) | 频繁项集 | [@刘海飞](https://github.com/WindZQ) | 1049498972 |\\n| 机器学习实战 | [第 12 章: FP-growth 高效发现频繁项集](/docs/ml/12.md) | 频繁项集 | [@程威](https://github.com/mikechengwei) | 842725815 |\\n| 机器学习实战 | [第 13 章: 利用 PCA 来简化数据](/docs/ml/13.md) | 工具 | [@廖立娟](https://github.com/lljuan330) | 835670618 |\\n| 机器学习实战 | [第 14 章: 利用 SVD 来简化数据](/docs/ml/14.md) | 工具 | [@张俊皓](https://github.com/marsjhao) | 714974242 |\\n| 机器学习实战 | [第 15 章: 大数据与 MapReduce](/docs/ml/15.md) | 工具 | [@wnma3mz](https://github.com/wnma3mz) | 1003324213 |\\n| Ml项目实战 | [第 16 章: 推荐系统（已迁移）](/docs/ml/16.md) | 项目 | [推荐系统（迁移后地址）](https://github.com/apachecn/RecommenderSystems)  |  |\\n| 第一期的总结 | [2017-04-08: 第一期的总结](/docs/report/2017-04-08.md) | 总结 | 总结 | 529815144 |\\n\\n### 网站视频\\n\\n> [知乎问答-爆炸啦-机器学习该怎么入门？](https://www.zhihu.com/question/20691338/answer/248678328)\\n\\n当然我知道，第一句就会被吐槽，因为科班出身的人，不屑的吐了一口唾沫，说傻X，还评论 Andrew Ng 的视频。。\\n\\n我还知道还有一部分人，看 Andrew Ng 的视频就是看不懂，那神秘的数学推导，那迷之微笑的英文版的教学，我何尝又不是这样走过来的？？ 我的心可能比你们都痛，因为我在网上收藏过上10部《机器学习》相关视频，外加国内本土风格的教程: 7月+小象 等等，我都很难去听懂，直到有一天，被一个百度的高级算法分析师推荐说: 《机器学习实战》还不错，通俗易懂，你去试试？？\\n\\n我试了试，还好我的Python基础和调试能力还不错，基本上代码都调试过一遍，很多高大上的 \"理论+推导\"，在我眼中变成了几个 \"加减乘除+循环\"，我想这不就是像我这样的程序员想要的入门教程么？\\n\\n很多程序员说机器学习 TM 太难学了，是的，真 TM 难学，我想最难的是: 没有一本像《机器学习实战》那样的作者愿意以程序员 Coding 角度去给大家讲解！！\\n\\n最近几天，GitHub 涨了 300颗 star，加群的200人， 现在还在不断的增加++，我想大家可能都是感同身受吧！\\n\\n很多想入门新手就是被忽悠着收藏收藏再收藏，但是最后还是什么都没有学到，也就是\"资源收藏家\"，也许新手要的就是 [MachineLearning(机器学习) 学习路线图](https:/docs.apachecn.org/map)。没错，我可以给你们的一份，因为我们还通过视频记录下来我们的学习过程。水平当然也有限，不过对于新手入门，绝对没问题，如果你还不会，那算我输！！\\n\\n> 视频怎么看？\\n\\n![](img/ApacheCN-ML-bilibili-compare.jpg)\\n\\n1. 理论科班出身-建议去学习 Andrew Ng 的视频（Ng 的视频绝对是权威，这个毋庸置疑）\\n2. 编码能力强 - 建议看我们的[《机器学习实战-教学版》](https://space.bilibili.com/97678687/channel/collectiondetail?sid=707585)\\n3. 编码能力弱 - 建议看我们的[《机器学习实战-讨论版》](https://space.bilibili.com/97678687/channel/collectiondetail?sid=707596)，不过在看理论的时候，看 教学版-理论部分；讨论版的废话太多，不过在讲解代码的时候是一行一行讲解的；所以，根据自己的需求，自由的组合。\\n\\n> 【免费】数学教学视频 - 可汗学院 入门篇\\n\\n* [@于振梓]() 推荐: 可汗学院-网易公开课\\n\\n| 概率 | 统计 | 线性代数 |\\n| - | - | - |\\n| [可汗学院(概率)](http://open.163.com/special/Khan/probability.html)  | [可汗学院(统计学)](http://open.163.com/special/Khan/khstatistics.html)| [可汗学院(线性代数)](http://open.163.com/special/Khan/linearalgebra.html)\\n\\n> 机器学习视频 - ApacheCN 教学版\\n\\n|||\\n| - | - |\\n| AcFun | B站 |\\n| <a title=\"AcFun（机器学习视频）\" href=\"http://www.acfun.cn/u/12540256.aspx#page=1\" target=\"_blank\"><img width=\"290\" src=\"/docs/img/ApacheCN-ML-AcFun.jpg\"></a> | <a title=\"bilibili（机器学习视频）\" href=\"https://space.bilibili.com/97678687/channel/collectiondetail?sid=707585\" target=\"_blank\"><img width=\"290\" src=\"/docs/img/ApacheCN-ML-bilibili.jpg\"></a> |\\n| 优酷 | 网易云课堂 |\\n| <a title=\"YouKu（机器学习视频）\" href=\"http://i.youku.com/apachecn\" target=\"_blank\"><img width=\"290\" src=\"/docs/img/ApacheCM-ML-youku.jpg\"></a> | <a title=\"WangYiYunKeTang（机器学习视频）\" href=\"http://study.163.com/course/courseMain.htm?courseId=1004582003\" target=\"_blank\"><img width=\"290\" src=\"/docs/img/ApacheCM-ML-WangYiYunKeTang.png\"></a> |\\n\\n> 【免费】机器/深度学习视频 - 吴恩达\\n\\n| 机器学习 | 深度学习 |\\n| - | - |\\n| [吴恩达机器学习](http://study.163.com/course/courseMain.htm?courseId=1004570029) | [神经网络和深度学习](http://mooc.study.163.com/course/2001281002?tid=2001392029) |\\n\\n\\n## 2.深度学习\\n\\n> 支持版本 \\n\\n| Version | Supported          |\\n| ------- | ------------------ |\\n| 3.6.x   | :white_check_mark: |\\n| 2.7.x   | :x:                |\\n\\n### 入门基础\\n\\n1. [反向传递](/docs/dl/反向传递.md): https://www.cnblogs.com/charlotte77/p/5629865.html\\n2. [CNN原理](/docs/dl/CNN原理.md): http://www.cnblogs.com/charlotte77/p/7759802.html\\n3. [RNN原理](/docs/dl/RNN原理.md): https://blog.csdn.net/qq_39422642/article/details/78676567\\n4. [LSTM原理](/docs/dl/LSTM原理.md): https://blog.csdn.net/weixin_42111770/article/details/80900575\\n\\n### Pytorch - 教程\\n\\n-- 待更新\\n\\n### TensorFlow 2.0 - 教程\\n\\n-- 待更新\\n\\n> 目录结构:\\n\\n* [安装指南](/docs/TensorFlow2.x/安装指南.md)\\n* [Keras 快速入门](/docs/TensorFlow2.x/Keras快速入门.md)\\n* [实战项目 1 电影情感分类](/docs/TensorFlow2.x/实战项目_1_电影情感分类.md)\\n* [实战项目 2 汽车燃油效率](/docs/TensorFlow2.x/实战项目_2_汽车燃油效率.md)\\n* [实战项目 3 优化 过拟合和欠拟合](/docs/TensorFlow2.x/实战项目_3_优化_过拟合和欠拟合.md)\\n* [实战项目 4 古诗词自动生成](/docs/TensorFlow2.x/实战项目_4_古诗词自动生成.md)\\n\\n切分（分词）\\n\\n词性标注\\n\\n命名实体识别\\n\\n句法分析\\n\\nWordNet可以被看作是一个同义词词典\\n\\n词干提取（stemming）与词形还原（lemmatization）\\n\\n* https://www.biaodianfu.com/nltk.html/amp\\n\\nTensorFlow 2.0学习网址\\n* https://github.com/lyhue1991/eat_tensorflow2_in_30_days\\n\\n## 3.自然语言处理\\n\\n> 支持版本 \\n\\n| Version | Supported          |\\n| ------- | ------------------ |\\n| 3.6.x   | :white_check_mark: |\\n| 2.7.x   | :x:                |\\n\\n学习过程中-内心复杂的变化！！！\\n\\n```python\\n自从学习NLP以后，才发现国内与国外的典型区别:\\n1. 对资源的态度是完全相反的:\\n  1) 国内: 就好像为了名气，举办工作装逼的会议，就是没有干货，全部都是象征性的PPT介绍，不是针对在做的各位\\n  2）国外: 就好像是为了推动nlp进步一样，分享者各种干货资料和具体的实现。（特别是: python自然语言处理）\\n2. 论文的实现: \\n  1) 各种高大上的论文实现，却还是没看到一个像样的GitHub项目！（可能我的搜索能力差了点，一直没找到）\\n  2）国外就不举例了，我看不懂！\\n3. 开源的框架\\n  1）国外的开源框架:  tensorflow/pytorch 文档+教程+视频（官方提供）\\n  2) 国内的开源框架: 额额，还真举例不出来！但是牛逼吹得不比国外差！（MXNet虽然有众多国人参与开发，但不能算是国内开源框架。基于MXNet的动手学深度学习(http://zh.d2l.ai & https://discuss.gluon.ai/t/topic/753)中文教程,已经由沐神(李沐)以及阿斯顿·张讲授录制，公开发布(文档+第一季教程+视频）。)\\n每一次深入都要去翻墙，每一次深入都要Google，每一次看着国内的说: 哈工大、讯飞、中科大、百度、阿里多牛逼，但是资料还是得国外去找！\\n有时候真的挺恨的！真的有点瞧不起自己国内的技术环境！\\n\\n当然谢谢国内很多博客大佬，特别是一些入门的Demo和基本概念。【深入的水平有限，没看懂】\\n```\\n\\n![](nlp/img/F94581F64C21A1094A473397DFA42F9C.jpg)\\n\\n* **【入门须知】必须了解**: <https://github.com/apachecn/AiLearning/tree/master/nlp>\\n* **【入门教程】强烈推荐: PyTorch 自然语言处理**: <https://github.com/apachecn/NLP-with-PyTorch>\\n* Python 自然语言处理 第二版: <https://usyiyi.github.io/nlp-py-2e-zh>\\n* 推荐一个[liuhuanyong大佬](https://github.com/liuhuanyong)整理的nlp全面知识体系: <https://liuhuanyong.github.io>\\n* 开源 - 词向量库集合: \\n  * <https://www.cnblogs.com/Darwin2000/p/5786984.html>\\n  * <https://ai.tencent.com/ailab/nlp/embedding.html>\\n  * <https://blog.csdn.net/xiezj007/article/details/85073890>\\n  * <https://github.com/Embedding/Chinese-Word-Vectors>\\n  * <https://github.com/brightmart/nlp_chinese_corpus>\\n  * <https://github.com/codemayq/chinese_chatbot_corpus>\\n  * <https://github.com/candlewill/Dialog_Corpus>\\n\\n\\n### 1.使用场景 （百度公开课）\\n\\n> 第一部分 入门介绍\\n\\n* 1.) [自然语言处理入门介绍](/docs/nlp/1.自然语言处理入门介绍.md)\\n\\n> 第二部分 机器翻译\\n\\n* 2.) [机器翻译](/nlp/2.机器翻译.md)\\n\\n> 第三部分 篇章分析\\n\\n* 3.1.) [篇章分析-内容概述](/docs/nlp/3.1.篇章分析-内容概述.md)\\n* 3.2.) [篇章分析-内容标签](/docs/nlp/3.2.篇章分析-内容标签.md)\\n* 3.3.) [篇章分析-情感分析](/docs/nlp/3.3.篇章分析-情感分析.md)\\n* 3.4.) [篇章分析-自动摘要](/docs/nlp/3.4.篇章分析-自动摘要.md)\\n\\n> 第四部分 UNIT-语言理解与交互技术\\n\\n* 4.) [UNIT-语言理解与交互技术](/docs/nlp/4.UNIT-语言理解与交互技术.md)\\n\\n### 应用领域\\n\\n#### 中文分词: \\n\\n* 构建DAG图\\n* 动态规划查找，综合正反向（正向加权反向输出）求得DAG最大概率路径\\n* 使用了SBME语料训练了一套 HMM + Viterbi 模型，解决未登录词问题\\n\\n#### 1.文本分类（Text Classification）\\n\\n文本分类是指标记句子或文档，例如电子邮件垃圾邮件分类和情感分析。\\n\\n下面是一些很好的初学者文本分类数据集。\\n\\n1. [路透社Newswire主题分类](http://kdd.ics.uci.edu/databases/reuters21578/reuters21578.html)（路透社-21578）。1987年路透社出现的一系列新闻文件，按类别编制索引。[另见RCV1，RCV2和TRC2](http://trec.nist.gov/data/reuters/reuters.html)。\\n2. [IMDB电影评论情感分类（斯坦福）](http://ai.stanford.edu/~amaas/data/sentiment)。来自网站imdb.com的一系列电影评论及其积极或消极的情绪。\\n3. [新闻组电影评论情感分类（康奈尔）](http://www.cs.cornell.edu/people/pabo/movie-review-data/)。来自网站imdb.com的一系列电影评论及其积极或消极的情绪。\\n\\n有关更多信息，请参阅帖子: \\n[单标签文本分类的数据集](http://ana.cachopo.org/datasets-for-single-label-text-categorization)。\\n\\n> 情感分析\\n\\n比赛地址: https://www.kaggle.com/c/word2vec-nlp-tutorial\\n\\n* 方案一(0.86): WordCount + 朴素 Bayes\\n* 方案二(0.94): LDA + 分类模型（knn/决策树/逻辑回归/svm/xgboost/随机森林）\\n  * a) 决策树效果不是很好，这种连续特征不太适合的\\n  * b) 通过参数调整 200 个topic，信息量保存效果较优（计算主题）\\n* 方案三(0.72): word2vec + CNN\\n  * 说实话: 没有一个好的机器，是调不出来一个好的结果 (: 逃\\n\\n**通过AUC 来评估模型的效果**\\n\\n#### 2.语言模型（Language Modeling）\\n\\n语言建模涉及开发一种统计模型，用于预测句子中的下一个单词或一个单词中的下一个单词。它是语音识别和机器翻译等任务中的前置任务。\\n\\n它是语音识别和机器翻译等任务中的前置任务。\\n\\n下面是一些很好的初学者语言建模数据集。\\n\\n1. [古腾堡项目](https://www.gutenberg.org/)，一系列免费书籍，可以用纯文本检索各种语言。\\n2. 还有更多正式的语料库得到了很好的研究; 例如: \\n    [布朗大学现代美国英语标准语料库](https://en.wikipedia.org/wiki/Brown_Corpus)。大量英语单词样本。\\n    [谷歌10亿字语料库](https://github.com/ciprian-chelba/1-billion-word-language-modeling-benchmark)。\\n\\n> 新词发现\\n\\n* 中文分词新词发现\\n* python3利用互信息和左右信息熵的中文分词新词发现\\n* <https://github.com/zhanzecheng/Chinese_segment_augment>\\n\\n> 句子相似度识别\\n\\n* 项目地址: https://www.kaggle.com/c/quora-question-pairs\\n* 解决方案: word2vec + Bi-GRU\\n\\n> 文本纠错\\n\\n* bi-gram + levenshtein\\n\\n#### 3.图像字幕（Image Captioning）\\n\\nmage字幕是为给定图像生成文本描述的任务。\\n\\n下面是一些很好的初学者图像字幕数据集。\\n\\n1. [上下文中的公共对象（COCO）](http://mscoco.org/dataset/#overview)。包含超过12万张带描述的图像的集合\\n2. [Flickr 8K](http://nlp.cs.illinois.edu/HockenmaierGroup/8k-pictures.html)。从flickr.com获取的8千个描述图像的集合。\\n3. [Flickr 30K](http://shannon.cs.illinois.edu/DenotationGraph/)。从flickr.com获取的3万个描述图像的集合。\\n    欲了解更多，请看帖子: \\n\\n[探索图像字幕数据集，2016年](http://sidgan.me/technical/2016/01/09/Exploring-Datasets)\\n\\n#### 4.机器翻译（Machine Translation）\\n\\n机器翻译是将文本从一种语言翻译成另一种语言的任务。\\n\\n下面是一些很好的初学者机器翻译数据集。\\n\\n1. [加拿大第36届议会的协调国会议员](https://www.isi.edu/natural-language/download/hansard/)。成对的英语和法语句子。\\n2. [欧洲议会诉讼平行语料库1996-2011](http://www.statmt.org/europarl/)。句子对一套欧洲语言。\\n    有大量标准数据集用于年度机器翻译挑战; 看到: \\n\\n[统计机器翻译](http://www.statmt.org/)\\n\\n> 机器翻译\\n\\n* Encoder + Decoder(Attention)\\n* 参考案例: http://pytorch.apachecn.org/cn/tutorials/intermediate/seq2seq_translation_tutorial.html\\n\\n#### 5.问答系统（Question Answering）\\n\\n问答是一项任务，其中提供了一个句子或文本样本，从中提出问题并且必须回答问题。\\n\\n下面是一些很好的初学者问题回答数据集。\\n\\n1. [斯坦福问题回答数据集（SQuAD）](https://rajpurkar.github.io/SQuAD-explorer/)。回答有关维基百科文章的问题。\\n2. [Deepmind问题回答语料库](https://github.com/deepmind/rc-data)。从每日邮报回答有关新闻文章的问题。\\n3. [亚马逊问答数据](http://jmcauley.ucsd.edu/data/amazon/qa/)。回答有关亚马逊产品的问题。\\n    有关更多信息，请参阅帖子: \\n\\n[数据集: 我如何获得问答网站的语料库，如Quora或Yahoo Answers或Stack Overflow来分析答案质量？](https://www.quora.com/Datasets-How-can-I-get-corpus-of-a-question-answering-website-like-Quora-or-Yahoo-Answers-or-Stack-Overflow-for-analyzing-answer-quality)\\n\\n#### 6.语音识别（Speech Recognition）\\n\\n语音识别是将口语的音频转换为人类可读文本的任务。\\n\\n下面是一些很好的初学者语音识别数据集。\\n\\n1. [TIMIT声学 - 语音连续语音语料库](https://catalog.ldc.upenn.edu/LDC93S1)。不是免费的，但因其广泛使用而上市。口语美国英语和相关的转录。\\n2. [VoxForge](http://voxforge.org/)。用于构建用于语音识别的开源数据库的项目。\\n3. [LibriSpeech ASR语料库](http://www.openslr.org/12/)。从LibriVox收集的大量英语有声读物。\\n\\n#### 7.自动文摘（Document Summarization）\\n\\n文档摘要是创建较大文档的简短有意义描述的任务。\\n\\n下面是一些很好的初学者文档摘要数据集。\\n\\n1. [法律案例报告数据集](https://archive.ics.uci.edu/ml/datasets/Legal+Case+Reports)。收集了4000份法律案件及其摘要。\\n2. [TIPSTER文本摘要评估会议语料库](http://www-nlpir.nist.gov/related_projects/tipster_summac/cmp_lg.html)。收集了近200份文件及其摘要。\\n3. [英语新闻文本的AQUAINT语料库](https://catalog.ldc.upenn.edu/LDC2002T31)。不是免费的，而是广泛使用的。新闻文章的语料库。\\n    欲了解更多信息: \\n\\n[文档理解会议（DUC）任务](http://www-nlpir.nist.gov/projects/duc/data.html)。\\n[在哪里可以找到用于文本摘要的良好数据集？](https://www.quora.com/Where-can-I-find-good-data-sets-for-text-summarization)\\n\\n> 命名实体识别\\n\\n* Bi-LSTM CRF\\n* 参考案例: http://pytorch.apachecn.org/cn/tutorials/beginner/nlp/advanced_tutorial.html\\n* CRF推荐文档: https://www.jianshu.com/p/55755fc649b1\\n\\n> 文本摘要\\n\\n* **抽取式**\\n* word2vec + textrank\\n* word2vec推荐文档: https://www.zhihu.com/question/44832436/answer/266068967\\n* textrank推荐文档: https://blog.csdn.net/BaiHuaXiu123/article/details/77847232\\n\\n\\n## Graph图计算【慢慢更新】\\n\\n* 数据集: [https://github.com/apachecn/data/tree/master/graph](https://github.com/apachecn/data/tree/master/graph)\\n* 学习资料: spark graphX实战.pdf 【文件太大不方便提供，自己百度】\\n\\n## 知识图谱\\n\\n* 知识图谱，我只认 [SimmerChan](https://www.zhihu.com/people/simmerchan): [【知识图谱-给AI装个大脑】](https://zhuanlan.zhihu.com/knowledgegraph)\\n* 说实话，我是看这博主老哥写的博客长大的，写的真的是深入浅出。我很喜欢，所以就分享给大家，希望你们也喜欢。\\n\\n### 进一步阅读\\n\\n如果您希望更深入，本节提供了其他数据集列表。\\n\\n1. [维基百科研究中使用的文本数据集](https://en.wikipedia.org/wiki/List_of_datasets_for_machine_learning_research#Text_data)\\n2. [数据集: 计算语言学家和自然语言处理研究人员使用的主要文本语料库是什么？](https://www.quora.com/Datasets-What-are-the-major-text-corpora-used-by-computational-linguists-and-natural-language-processing-researchers-and-what-are-the-characteristics-biases-of-each-corpus)\\n3. [斯坦福统计自然语言处理语料库](https://nlp.stanford.edu/links/statnlp.html#Corpora)\\n4. [按字母顺序排列的NLP数据集列表](https://github.com/niderhoff/nlp-datasets)\\n5. [该机构NLTK](http://www.nltk.org/nltk_data/)\\n6. [在DL4J上打开深度学习数据](https://deeplearning4j.org/opendata)\\n7. [NLP数据集](https://github.com/caesar0301/awesome-public-datasets#natural-language)\\n8. 国内开放数据集: https://bosonnlp.com/dev/resource\\n\\n\\n## 参考\\n\\n* [比赛收集平台](https://github.com/iphysresearch/DataSciComp)\\n* [pbharrin/machinelearninginaction](https://github.com/pbharrin/machinelearninginaction)\\n* [ML Mastery](https://machinelearningmastery.com/datasets-natural-language-processing)\\n\\n## 致谢\\n\\n最近无意收到群友推送的链接，发现得到大佬高度的认可，并在热心的推广。在此感谢:\\n\\n* [量子位](https://www.zhihu.com/question/20472776/answer/691646493)\\n* [人工智能前沿讲习](https://mp.weixin.qq.com/s/f2dqulxOPkt7k5hqPsydyQ)\\n\\n## 赞助我们\\n\\n<img src=\"http://data.apachecn.org/img/about/donate.jpg\" alt=\"微信&支付宝\" />\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[1]['readme_contents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7701c38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p aligncenter hrefhttpswwwapachecnorg img width200 srcdocsimglogojpg br hrefhttpswwwapachecnorgimg srchttpsimgshieldsiobadge3ehomegreensvga hrefhttpshomeapachecnorgaboutimg srchttpsimgshieldsiobadge3eaboutgreensvga hrefmailtoapache163comimg srchttpsimgshieldsiobadge3eemailgreensvga p h1 aligncentera hrefhttpsgithubcomapachecnailearningai learningah1 cc byncsa 40httpscreativecommonsorglicensesbyncsa40deedzh stewart brand httpsailearningapachecnorg v1httpsalv1apachecnorg quantlearninghttpsqlearnapachecnorg apachecn 713436582httpsqmqqcomcgibinqmqrk5u_aauyly3fhm8mextjzbeo2boqiusjump_fromwebapiauthkeycvzcremtvkdtxzbq8lyjwncxiszzwolrx5hybx5psrku6s0fvgx54vhhlgynt apachecn httpswwwapachecnorg apachecn163com 1 2 3 httpsgithubcomapachecnairoadmap httpswwwixiguacompseries6822642486343631363 httpswwwixiguacompseries6822563009391493636 httpswwwixiguacompseries6822816341615968772 nlp httpswwwixiguacompseries6828241431295951373 ai httpsgithubcomapachecnailearningtreemasteraimd 1 version supported 36x x 27x white_check_mark 27x 36x machine learning action httpsgithubcomapachecndata httpsgithubcomapachecndataissues3 httpsgithubcomapachecndatatreemasterbook httpsgithubcomapachecndatatreemaster httpsgithubcomapachecndatatreemaster httpsgithubcomapachecndatatreemaster bilibili acfun httpsgithubcomredstonewill httpsgithubcomapachecnntuhsuantienlinml httpsfeiskyxyzmachinelearning httpsfeiskyxyzmachinelearning github qq 1 docsml1md httpsgithubcomelmadavies 1306014226 2 knn docsml2md httpsgithubcomyouyj521 279393323 3 docsml3md httpsgithubcomjingwangfei 844300439 4 docsml4md wnma3mzhttpsgithubcomwnma3mzbrhttpsgithubcomkailian 1003324213br244970749 5 logisticdocsml5md httpsgithubcomdatamonk2017 529925688 6 svm docsml6md httpsgithubcomvprincekin 934969547 7 adaboostdocsml7md httpsgithubcomjiangzhonglian 529815144 8 docsml8md httpsgithubcomdatamonk2017 529925688 9 docsml9md httpsgithubcomdatamonk2017 529925688 10 kmeans docsml10md httpsgithubcomxuzhaoqing 827106588 11 apriori docsml11md httpsgithubcomwindzq 1049498972 12 fpgrowth docsml12md httpsgithubcommikechengwei 842725815 13 pca docsml13md httpsgithubcomlljuan330 835670618 14 svd docsml14md httpsgithubcommarsjhao 714974242 15 mapreducedocsml15md wnma3mzhttpsgithubcomwnma3mz 1003324213 ml 16 docsml16md httpsgithubcomapachecnrecommendersystems 20170408 docsreport20170408md 529815144 httpswwwzhihucomquestion20691338answer248678328 x andrew ng andrew ng 10 7 tm tm coding github 300 star200 machinelearning httpsdocsapachecnorgmap imgapachecnmlbilibilicomparejpg 1 andrew ng ng 2 httpsspacebilibilicom97678687channelcollectiondetailsid707585 3 httpsspacebilibilicom97678687channelcollectiondetailsid707596 httpopen163comspecialkhanprobabilityhtml httpopen163comspecialkhankhstatisticshtml httpopen163comspecialkhanlinearalgebrahtml apachecn acfun b titleacfun hrefhttpwwwacfuncnu12540256aspxpage1 target_blankimg width290 srcdocsimgapachecnmlacfunjpga titlebilibili hrefhttpsspacebilibilicom97678687channelcollectiondetailsid707585 target_blankimg width290 srcdocsimgapachecnmlbilibilijpga titleyouku hrefhttpiyoukucomapachecn target_blankimg width290 srcdocsimgapachecmmlyoukujpga titlewangyiyunketang hrefhttpstudy163comcoursecoursemainhtmcourseid1004582003 target_blankimg width290 srcdocsimgapachecmmlwangyiyunketangpnga httpstudy163comcoursecoursemainhtmcourseid1004570029 httpmoocstudy163comcourse2001281002tid2001392029 2 version supported 36x white_check_mark 27x x 1 docsdlmd httpswwwcnblogscomcharlotte77p5629865html 2 cnndocsdlcnnmd httpwwwcnblogscomcharlotte77p7759802html 3 rnndocsdlrnnmd httpsblogcsdnnetqq_39422642articledetails78676567 4 lstmdocsdllstmmd httpsblogcsdnnetweixin_42111770articledetails80900575 pytorch tensorflow 20 docstensorflow2xmd kera docstensorflow2xkerasmd 1 docstensorflow2x_1_md 2 docstensorflow2x_2_md 3 docstensorflow2x_3__md 4 docstensorflow2x_4_md wordnet stemminglemmatization httpswwwbiaodianfucomnltkhtmlamp tensorflow 20 httpsgithubcomlyhue1991eat_tensorflow2_in_30_days 3 version supported 36x white_check_mark 27x x nlp 1 1 ppt 2 nlp 2 1 github 2 3 1 tensorflowpytorch 2 mxnetmxnethttpzhd2lai httpsdiscussgluonaittopic753 google demo nlpimgf94581f64c21a1094a473397dfa42f9cjpg httpsgithubcomapachecnailearningtreemasternlp pytorch httpsgithubcomapachecnnlpwithpytorch httpsusyiyigithubionlppy2ezh liuhuanyonghttpsgithubcomliuhuanyongnlp httpsliuhuanyonggithubio httpswwwcnblogscomdarwin2000p5786984html httpsaitencentcomailabnlpembeddinghtml httpsblogcsdnnetxiezj007articledetails85073890 httpsgithubcomembeddingchinesewordvectors httpsgithubcombrightmartnlp_chinese_corpus httpsgithubcomcodemayqchinese_chatbot_corpus httpsgithubcomcandlewilldialog_corpus 1 1 docsnlp1md 2 nlp2md 31 docsnlp31md 32 docsnlp32md 33 docsnlp33md 34 docsnlp34md unit 4 unitdocsnlp4unitmd dag dag sbme hmm viterbi 1text classification 1 newswirehttpkddicsuciedudatabasesreuters21578reuters21578html215781987rcv1rcv2trc2httptrecnistgovdatareutersreutershtml 2 imdbhttpaistanfordeduamaasdatasentimentimdbcom 3 httpwwwcscornelledupeoplepabomoviereviewdataimdbcom httpanacachopoorgdatasetsforsinglelabeltextcategorization httpswwwkagglecomcword2vecnlptutorial 086 wordcount bayes 094 lda knnsvmxgboost b 200 topic 072 word2vec cnn auc 2language modeling 1 httpswwwgutenbergorg 2 httpsenwikipediaorgwikibrown_corpus 10httpsgithubcomciprianchelba1billionwordlanguagemodelingbenchmark  httpsgithubcomzhanzechengchinese_segment_augment httpswwwkagglecomcquoraquestionpairs word2vec bigru bigram levenshtein 3image captioning mage 1 cocohttpmscocoorgdatasetoverview12 2 flickr 8khttpnlpcsillinoiseduhockenmaiergroup8kpictureshtmlflickrcom8 3 flickr 30khttpshannoncsillinoisedudenotationgraphflickrcom3 2016httpsidganmetechnical20160109exploringdatasets 4machine translation 1 36httpswwwisiedunaturallanguagedownloadhansard 2 19962011httpwwwstatmtorgeuroparl httpwwwstatmtorg encoder decoderattention httppytorchapachecnorgcntutorialsintermediateseq2seq_translation_tutorialhtml 5question answering 1 squadhttpsrajpurkargithubiosquadexplorer 2 deepmindhttpsgithubcomdeepmindrcdata 3 httpjmcauleyucsdedudataamazonqa quorayahoo answersstack overflowhttpswwwquoracomdatasetshowcanigetcorpusofaquestionansweringwebsitelikequoraoryahooanswersorstackoverflowforanalyzinganswerquality 6speech recognition 1 timit httpscatalogldcupenneduldc93s1 2 voxforgehttpvoxforgeorg 3 librispeech asrhttpwwwopenslrorg12librivox 7document summarization 1 httpsarchiveicsuciedumldatasetslegalcasereports4000 2 tipsterhttpwwwnlpirnistgovrelated_projectstipster_summaccmp_lghtml200 3 aquainthttpscatalogldcupenneduldc2002t31 duchttpwwwnlpirnistgovprojectsducdatahtml httpswwwquoracomwherecanifindgooddatasetsfortextsummarization bilstm crf httppytorchapachecnorgcntutorialsbeginnernlpadvanced_tutorialhtml crf httpswwwjianshucomp55755fc649b1 word2vec textrank word2vec httpswwwzhihucomquestion44832436answer266068967 textrank httpsblogcsdnnetbaihuaxiu123articledetails77847232 graph httpsgithubcomapachecndatatreemastergraphhttpsgithubcomapachecndatatreemastergraph spark graphxpdf simmerchanhttpswwwzhihucompeoplesimmerchan aihttpszhuanlanzhihucomknowledgegraph 1 httpsenwikipediaorgwikilist_of_datasets_for_machine_learning_researchtext_data 2 httpswwwquoracomdatasetswhatarethemajortextcorporausedbycomputationallinguistsandnaturallanguageprocessingresearchersandwhatarethecharacteristicsbiasesofeachcorpus 3 httpsnlpstanfordedulinksstatnlphtmlcorpora 4 nlphttpsgithubcomniderhoffnlpdatasets 5 nltkhttpwwwnltkorgnltk_data 6 dl4jhttpsdeeplearning4jorgopendata 7 nlphttpsgithubcomcaesar0301awesomepublicdatasetsnaturallanguage 8 httpsbosonnlpcomdevresource httpsgithubcomiphysresearchdatascicomp pbharrinmachinelearninginactionhttpsgithubcompbharrinmachinelearninginaction ml masteryhttpsmachinelearningmasterycomdatasetsnaturallanguageprocessing httpswwwzhihucomquestion20472776answer691646493 httpsmpweixinqqcomsf2dqulxopkt7k5hqpsydyq img srchttpdataapachecnorgimgaboutdonatejpg alt'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[1]['cleaned_readme_contents']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21acc00c",
   "metadata": {},
   "source": [
    "## There are a lot of http address links in this text. lets remove those since they are all going to be useless for nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0bed062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'copyright 2020 huggingface team right reserved licensed apache license version 20 license may use file except compliance license may obtain copy license 20 unless required applicable law agreed writing software distributed license distributed basis without warranty condition kind either express implied see license specific language governing permission limitation license p aligncenter picture source mediapreferscolorscheme dark  source mediapreferscolorscheme light  img althugging face transformer library  width352 height59 stylemaxwidth 100 picture br br p p aligncenter  img altbuild   img altgithub   img altdocumentation _colorreddown_messageofflineup_messageonline  img altgithub release  _of_conductmd img altcontributor covenant 20covenantv2020adoptedff69b4svg 155220641img 155220641svg altdoia p h4 aligncenter p benglishb _zhhansmda _zhhantmda _komda _esmdespanola _jamda _hdmda p h4 h3 aligncenter pstateoftheart machine learning jax pytorch tensorflowp h3 h3 aligncenter  _bannerpnga h3 transformer provides thousand pretrained model perform task different modality text vision audio model applied text task like text classification information extraction question answering summarization translation text generation 100 language image task like image classification object detection segmentation audio task like speech recognition audio classification transformer model also perform task several modality combined table question answering optical character recognition information extraction scanned document video classification visual question answering transformer provides apis quickly download use pretrained model given text finetune datasets share community model  time module defining architecture fully standalone modified enable quick research experiment transformer backed three popular deep learning library    seamless integration straightforward train model one loading inference online demo test model directly page model  also offer private model hosting versioning inference  public private model example natural language processing masked word completion 5bmask5doffrance name entity recognition 03englishtextmynameissarahandiliveinlondoncity text generation gpt22textalongtimeago2c natural language inference  summarization 324metres2812c063ft29tall2caboutthesameheightasan81storeybuilding2candthetalleststructureinparisitsbaseissquare2cmeasuring125metres28410ft29oneachsideduringitsconstruction2ctheeiffeltowersurpassedthewashingtonmonumenttobecomethetallestmanmadestructureintheworld2catitleitheldfor41yearsuntilthechryslerbuildinginnewyorkcitywasfinishedin1930itwasthefirststructuretoreachaheightof300metresduetotheadditionofabroadcastingaerialatthetopofthetowerin19572citisnowtallerthanthechryslerbuildingby52metres2817ft29excludingtransmitters2ctheeiffeltoweristhesecondtallestfreestandingstructureinfranceafterthemillauviaduct question answering 3fcontexttheamazonrainforest28portuguese3aflorestaamazc3b4nicaoramazc3b4nia3bspanish3aselvaamazc3b3nica2camazonc3adaorusuallyamazonia3bfrench3aforc3aatamazonienne3bdutch3aamazoneregenwoud292calsoknowninenglishasamazoniaortheamazonjungle2cisamoistbroadleafforestthatcoversmostoftheamazonbasinofsouthamericathisbasinencompasses72c0002c000squarekilometres2822c7002c000sqmi292cofwhich52c5002c000squarekilometres2822c1002c000sqmi29arecoveredbytherainforestthisregionincludesterritorybelongingtoninenationsthemajorityoftheforestiscontainedwithinbrazil2cwith6025oftherainforest2cfollowedbyperuwith13252ccolombiawith10252candwithminoramountsinvenezuela2cecuador2cbolivia2cguyana2csurinameandfrenchguianastatesordepartmentsinfournationscontain22amazonas22intheirnamestheamazonrepresentsoverhalfoftheplanet27sremainingrainforests2candcomprisesthelargestandmostbiodiversetractoftropicalrainforestintheworld2cwithanestimated390billionindividualtreesdividedinto162c000species translation t55basetextmynameiswolfgangandiliveinberlin computer vision image classification 16224 object detection 50 semantic segmentation 0finetunedade512512 panoptic segmentation  depth estimation _docdpt video classification _docvideomae universal segmentation _ade20k_dinat_large audio automatic speech recognition wav2vec22vec2base960h keyword spotting wav2vec22vec2basesuperbks audio classification audio spectrogram 101004593 multimodal task table question answering  visual question answering 32finetunedvqa zeroshot image classification 14 document question answering  zeroshot video classification _docxclip write  built hugging face team official demo repos text generation capability looking custom support hugging face team target_blank  img althuggingface expert acceleration program  stylemaxwidth 600px border 1px solid eee borderradius 4px boxshadow 0 1px 2px 0 rgba0 0 0 005 abr quick tour immediately use model given input text image audio provide pipeline api pipeline group together pretrained model preprocessing wa used model training quickly use pipeline classify positive versus negative text transformer import pipeline allocate pipeline sentimentanalysis classifier pipelinesentimentanalysis classifierwe happy introduce pipeline transformer repository label positive score 09996980428695679 second line code downloads cache pretrained model used pipeline third evaluates given text answer positive confidence 9997 many task pretrained pipeline ready go nlp also computer vision speech example easily extract detected object image import request pil import image transformer import pipeline download image cute cat url _samplepng image_data requestsgeturl streamtrueraw image imageopenimage_data allocate pipeline object detection object_detector pipelineobjectdetection object_detectorimage score 09982201457023621 label remote box xmin 40 ymin 70 xmax 175 ymax 117 score 09960021376609802 label remote box xmin 333 ymin 72 xmax 368 ymax 187 score 09954745173454285 label couch box xmin 0 ymin 1 xmax 639 ymax 473 score 09988006353378296 label cat box xmin 13 ymin 52 xmax 314 ymax 470 score 09986783862113953 label cat box xmin 345 ymin 23 xmax 640 ymax 368 get list object detected image box surrounding object confidence score original image left prediction displayed right h3 aligncenter aimg _samplepng width400a aimg _sample_post_processedpng width400a h3 learn task supported pipeline api _summary addition pipeline download use pretrained model given task take three line code pytorch version transformer import autotokenizer automodel tokenizer autotokenizerfrom_pretrainedbertbaseuncased model automodelfrom_pretrainedbertbaseuncased input tokenizerhello world return_tensorspt output modelinputs equivalent code tensorflow transformer import autotokenizer tfautomodel tokenizer autotokenizerfrom_pretrainedbertbaseuncased model tfautomodelfrom_pretrainedbertbaseuncased input tokenizerhello world return_tensorstf output modelinputs tokenizer responsible preprocessing pretrained model expects called directly single string example list output dictionary use downstream code simply directly pas model using argument unpacking operator model regular pytorch  tensorflow _docfkerasmodel depending backend use usual  explains integrate model classic pytorch tensorflow training loop use trainer api quickly finetune new dataset use transformer 1 easytouse stateoftheart model high performance natural language understanding generation computer vision audio task low barrier entry educator practitioner userfacing abstraction three class learn unified api using pretrained model 1 lower compute cost smaller carbon footprint researcher share trained model instead always retraining practitioner reduce compute time production cost dozen architecture 60000 pretrained model across modality 1 choose right framework every part model lifetime train stateoftheart model 3 line code move single model tf20pytorchjax framework seamlessly pick right framework training evaluation production 1 easily customize model example need provide example architecture reproduce result published original author model internals exposed consistently possible model file used independently library quick experiment shouldnt use transformer library modular toolbox building block neural net code model file refactored additional abstraction purpose researcher quickly iterate model without diving additional abstractionsfiles training api intended work model optimized work model provided library generic machine learning loop use another library possibly  strive present many use case possible script example  example expected wont work outofthe box specific problem required change line code adapt need installation pip repository tested 36 flax 032 pytorch 131 tensorflow 23 install transformer virtual 3libraryvenvhtml youre unfamiliar virtual environment check user  first create virtual environment version youre going use activate need install least one flax pytorch tensorflow please refer tensorflow installation  pytorch installation  andor   installation page regarding specific installation command platform one backends ha installed transformer installed using pip follows bash pip install transformer youd like play example need bleeding edge code cant wait new release must install library  conda since transformer version v400 conda channel huggingface transformer installed using conda follows shell script conda install c huggingface transformer follow installation page flax pytorch tensorflow see install conda _note_ window may prompted activate developer mode order benefit caching option please let u know _hubissues1062 model architecture model  provided transformer seamlessly integrated huggingfaceco model  uploaded directly   current number checkpoint  transformer currently provides following architecture see _summary highlevel summary 1 _docalbert google research toyota technological institute chicago released paper albert lite bert selfsupervised learning language 190911942 zhenzhong lan mingda chen sebastian goodman kevin gimpel piyush sharma radu soricut 1 _docalign google research released paper scaling visual visionlanguage representation learning noisy text 210205918 chao jia yinfei yang ye xia yiting chen zarana parekh hieu pham quoc v le yunhsuan sung zhen li tom duerig 1 _docaltclip baai released paper altclip altering language encoder clip extended language 221106679 chen zhongzhi liu guang zhang bowen ye fulong yang qinghong wu ledell 1 audio spectrogram _docaudiospectrogramtransformer mit released paper ast audio spectrogram 210401778 yuan gong yuan chung james glass 1 _docbart facebook released paper bart denoising sequencetosequence pretraining natural language generation translation 191013461 mike lewis yinhan liu naman goyal marjan ghazvininejad abdelrahman mohamed omer levy f stoyanov luke zettlemoyer 1 _docbarthez ecole polytechnique released paper barthez skilled pretrained french sequencetosequence 201012321 moussa kamal eddine antoine jp tixier michalis vazirgiannis 1 _docbartpho vinai research released paper bartpho pretrained sequencetosequence model 210909701 nguyen luong tran duong minh le dat quoc nguyen 1 _docbeit microsoft released paper beit bert pretraining image 210608254 hangbo bao li dong furu wei 1 _docbert google released paper bert pretraining deep bidirectional transformer language 181004805 jacob devlin mingwei chang kenton lee kristina toutanova 1 bert sequence _docbertgeneration google released paper leveraging pretrained checkpoint sequence generation 190712461 sascha rothe shashi narayan aliaksei severyn 1 _docbertweet vinai research released paper bertweet pretrained language model english 2020emnlpdemos2 dat quoc nguyen thanh vu anh tuan nguyen 1 _docbigbird_pegasus google research released paper big bird transformer longer 200714062 manzil zaheer guru guruganesh avinava dubey joshua ainslie chris alberti santiago ontanon philip pham anirudh ravula qifan wang li yang amr ahmed 1 _docbig_bird google research released paper big bird transformer longer 200714062 manzil zaheer guru guruganesh avinava dubey joshua ainslie chris alberti santiago ontanon philip pham anirudh ravula qifan wang li yang amr ahmed 1 _docbiogpt microsoft research ai4science released paper biogpt generative pretrained transformer biomedical text generation 101093bibbbac4096713511guestaccesskeya66d9b5d4f834017bb52405815c907b9 renqian luo liai sun yingce xia tao qin sheng zhang hoifung poon tieyan liu 1 _docbit google ai released paper big transfer bit general visual representation 191211370 alexander kolesnikov lucas beyer xiaohua zhai joan puigcerver jessica yung sylvain gelly neil houlsby 1 _docblenderbot facebook released paper recipe building opendomain 200413637 stephen roller emily dinan naman goyal da ju mary williamson yinhan liu jing xu myle ott kurt shuster eric smith ylan boureau jason weston 1 _docblenderbotsmall facebook released paper recipe building opendomain 200413637 stephen roller emily dinan naman goyal da ju mary williamson yinhan liu jing xu myle ott kurt shuster eric smith ylan boureau jason weston 1 _docblip salesforce released paper blip bootstrapping languageimage pretraining unified visionlanguage understanding 220112086 junnan li dongxu li caiming xiong steven hoi 1 blip2_docblip2 salesforce released paper blip2 bootstrapping languageimage pretraining frozen image encoders large language 230112597 junnan li dongxu li silvio savarese steven hoi 1 _docbloom bigscience workshop released bigscience  1 _docbort alexa released paper optimal subarchitecture extraction 201010499 adrian de wynter daniel j perry 1 _docbridgetower harbin institute technologymicrosoft research asiaintel lab released paper bridgetower building bridge encoders visionlanguage representation 220608657 xiao xu chenfei wu shachar rosenman vasudev lal wanxiang che nan duan 1 byt5_docbyt5 google research released paper byt5 towards tokenfree future pretrained bytetobyte 210513626 linting xue aditya barua noah constant ramus alrfou sharan narang mihir kale adam robert colin raffel 1 _doccamembert inriafacebooksorbonne released paper camembert tasty french language 191103894 louis martin benjamin muller pedro javier ortiz suarez yoann dupont laurent romary eric villemonte de la clergerie djame seddah benoit sagot 1 _doccanine google research released paper canine pretraining efficient tokenizationfree encoder language 210306874 jonathan h clark dan garrette iulia turc john wieting 1 _docchinese_clip ofasys released paper chinese clip contrastive visionlanguage pretraining 221101335 yang junshu pan junyang lin rui men yichang zhang jingren zhou chang zhou 1 _docclap laionai released paper largescale contrastive languageaudio pretraining feature fusion keywordtocaption 221106687 yusong wu ke chen tianyu zhang yuchen hui taylor bergkirkpatrick shlomo dubnov 1 _docclip openai released paper learning transferable visual model natural language 210300020 alec radford jong wook kim chris hallacy aditya ramesh gabriel goh sandhini agarwal girish sastry amanda askell pamela mishkin jack clark gretchen krueger ilya sutskever 1 _docclipseg university gottingen released paper image segmentation using text image 211210003 timo luddecke alexander ecker 1 _doccodegen salesforce released paper conversational paradigm program 220313474 erik nijkamp bo pang hiroaki hayashi lifu tu huan wang yingbo zhou silvio savarese caiming xiong 1 conditional _docconditional_detr microsoft research asia released paper conditional detr fast training 210806152 depu meng xiaokang chen zejia fan gang zeng houqiang li yuhui yuan lei sun jingdong wang 1 _docconvbert yitutech released paper convbert improving bert spanbased dynamic 200802496 zihang jiang weihao yu daquan zhou yunpeng chen jiashi feng shuicheng yan 1 _docconvnext facebook ai released paper convnet 2020220103545 zhuang liu hanzi mao chaoyuan wu christoph feichtenhofer trevor darrell saining xie 1 convnextv2_docconvnextv2 facebook ai released paper convnext v2 codesigning scaling convnets masked 230100808 sanghyun woo shoubhik debnath ronghang hu xinlei chen zhuang liu kweon saining xie 1 _doccpm tsinghua university released paper cpm largescale generative chinese pretrained language 201200413 zhengyan zhang xu han hao zhou pei ke yuxian gu deming ye yujia qin yusheng su haozhe ji jian guan fanchao qi xiaozhi wang yanan zheng guoyang zeng huanqi cao shengqi chen daixuan li zhenbo sun zhiyuan liu minlie huang wentao han jie tang juanzi li xiaoyan zhu maosong sun 1 _doccpmant openbmb released  1 _docctrl salesforce released paper ctrl conditional transformer language model controllable 190905858 nitish shirish keskar bryan mccann lav r varshney caiming xiong richard socher 1 _doccvt microsoft released paper cvt introducing convolution vision 210315808 haiping wu bin xiao noel codella mengchen liu xiyang dai lu yuan lei zhang 1 data2_docdata2vec facebook released paper data2vec general framework selfsupervised learning speech vision 220203555 alexei baevski weining hsu qiantong xu arun babu jiatao gu michael auli 1 _docdeberta microsoft released paper deberta decodingenhanced bert disentangled 200603654 pengcheng xiaodong liu jianfeng gao weizhu chen 1 debertav2_docdebertav2 microsoft released paper deberta decodingenhanced bert disentangled 200603654 pengcheng xiaodong liu jianfeng gao weizhu chen 1 decision _docdecision_transformer berkeleyfacebookgoogle released paper decision transformer reinforcement learning via sequence 210601345 lili chen kevin lu aravind rajeswaran kimin lee aditya grover michael laskin pieter abbeel aravind srinivas igor mordatch 1 deformable _docdeformable_detr sensetime research released paper deformable detr deformable transformer endtoend object 201004159 xizhou zhu weijie su lewei lu bin li xiaogang wang jifeng dai 1 _docdeit facebook released paper training dataefficient image transformer distillation 201212877 hugo touvron matthieu cord matthijs douze francisco massa alexandre sablayrolles herve jegou 1 _docdeplot google ai released paper deplot oneshot visual language reasoning plottotable 221210505 fangyu liu julian martin eisenschlos francesco piccinno syrine krichene chenxi pang kenton lee mandar joshi wenhu chen nigel collier yasemin altun 1 _docdeta university texas austin released paper nm strike 221206137 jeffrey ouyangzhang jang hyun cho xingyi zhou philipp krahenbuhl 1 _docdetr facebook released paper endtoend object detection 200512872 nicolas carion francisco massa gabriel synnaeve nicolas usunier alexander kirillov sergey zagoruyko 1 _docdialogpt microsoft research released paper dialogpt largescale generative pretraining conversational response 191100536 yizhe zhang siqi sun michel galley yenchun chen chris brockett xiang gao jianfeng gao jingjing liu bill dolan 1 _docdinat shi lab released paper dilated neighborhood attention 220915001 ali hassani humphrey shi 1 _docdistilbert huggingface released together paper distilbert distilled version bert smaller faster cheaper 191001108 victor sanh lysandre debut thomas wolf method ha applied compress gpt2 distilgpt2_projectsdistillation roberta _projectsdistillation multilingual bert _projectsdistillation german version distilbert 1 _docdit microsoft research released paper dit selfsupervised pretraining document image 220302378 junlong li yiheng xu tengchao lv lei cui cha zhang furu wei 1 _docdonut naver released together paper ocrfree document understanding 211115664 geewook kim teakgyu hong moonbin yim jeongyeon nam jinyoung park jinyeong yim wonseok hwang sangdoo yun dongyoon han seunghyun park 1 _docdpr facebook released paper dense passage retrieval opendomain question 200404906 vladimir karpukhin barlas oguz sewon min patrick lewis ledell wu sergey edunov danqi chen wentau yih 1 _docdpt intel lab released paper vision transformer dense 210313413 rene ranftl alexey bochkovskiy vladlen koltun 1 _docefficientformer snap research released paper efficientformer vision transformer 220601191 yanyu li geng yuan yang wen ju hu georgios evangelidis sergey tulyakov yanzhi wang jian ren 1 _docefficientnet google brain released paper efficientnet rethinking model scaling convolutional neural 190511946 mingxing tan quoc v le 1 _docelectra google researchstanford university released paper electra pretraining text encoders discriminator rather 200310555 kevin clark minhthang luong quoc v le christopher manning 1 _docencoderdecoder google research released paper leveraging pretrained checkpoint sequence generation 190712461 sascha rothe shashi narayan aliaksei severyn 1 _docernie baidu released paper ernie enhanced representation knowledge 190409223 yu sun shuohuan wang yukun li shikun feng xuyi chen han zhang xin tian danxiang zhu hao tian hua wu 1 _docernie_m baidu released paper erniem enhanced multilingual representation aligning crosslingual semantics monolingual 201215674 xuan ouyang shuohuan wang chao pang yu sun hao tian hua wu haifeng wang 1 _docesm meta ai transformer protein language model esm1b wa released paper biological structure function emerge scaling unsupervised learning 250 million protein 11815e2016239118 alexander rives joshua meier tom sercu siddharth goyal zeming lin jason liu demi guo myle ott c lawrence zitnick jerry rob fergus esm1v wa released paper language model enable zeroshot prediction effect mutation protein 10110120210709450648 joshua meier roshan rao robert verkuil jason liu tom sercu alexander rives esm2 esmfold released paper language model protein sequence scale evolution enable accurate structure 10110120220720500902 zeming lin halil akin roshan rao brian hie zhongkai zhu wenting lu allan santos costa maryam fazelzarandi tom sercu sal candido alexander rives 1 flant5_docflant5 google ai released repository googleresearcht55xblobmaindocsmodelsmdflant5checkpoints hyung chung le hou shayne longpre barret zoph yi tay william fedus eric li xuezhi wang mostafa dehghani siddhartha brahma albert webson shixiang shane gu zhuyun dai mirac suzgun xinyun chen aakanksha chowdhery sharan narang gaurav mishra adam yu vincent zhao yanping huang andrew dai hongkun yu slav petrov ed h chi jeff dean jacob devlin adam robert denny zhou quoc v le jason wei 1 flanul2_docflanul2 google ai released repository googleresearcht55xblobmaindocsmodelsmdflanul2checkpoints hyung chung le hou shayne longpre barret zoph yi tay william fedus eric li xuezhi wang mostafa dehghani siddhartha brahma albert webson shixiang shane gu zhuyun dai mirac suzgun xinyun chen aakanksha chowdhery sharan narang gaurav mishra adam yu vincent zhao yanping huang andrew dai hongkun yu slav petrov ed h chi jeff dean jacob devlin adam robert denny zhou quoc v le jason wei 1 _docflaubert cnrs released paper flaubert unsupervised language model pretraining 191205372 hang le loic vial jibril frej vincent segonne maximin coavoux benjamin lecouteux alexandre allauzen benoit crabbe laurent besacier didier schwab 1 _docflava facebook ai released paper flava foundational language vision alignment 211204482 amanpreet singh ronghang hu vedanuj goswami guillaume couairon wojciech galuba marcus rohrbach douwe kiela 1 _docfnet google research released paper fnet mixing token fourier 210503824 james leethorp joshua ainslie ilya eckstein santiago ontanon 1 _docfocalnet microsoft research released paper focal modulation 220311926 jianwei yang chunyuan li xiyang dai lu yuan jianfeng gao 1 funnel _docfunnel cmugoogle brain released paper funneltransformer filtering sequential redundancy efficient language 200603236 zihang dai guokun lai yiming yang quoc v le 1 _docgit microsoft research released paper git generative imagetotext transformer vision 220514100 jianfeng wang zhengyuan yang xiaowei hu linjie li kevin lin zhe gan zicheng liu ce liu lijuan wang 1 _docglpn kaist released paper globallocal path network monocular depth estimation vertical 220107436 doyeon kim woonghyun ga pyungwhan ahn donggyu joo sehwan chun junmo kim 1 _docopenaigpt openai released paper improving language understanding generative  alec radford karthik narasimhan tim salimans ilya sutskever 1 gpt _docgpt_neo eleutherai released repository  sid black stella biderman leo gao phil wang connor leahy 1 gpt _docgpt_neox eleutherai released paper gptneox20b opensource autoregressive language 220406745 sid black stella biderman eric hallahan quentin anthony leo gao laurence golding horace connor leahy kyle mcdonell jason phang michael pieler usvsn sai prashanth shivanshu purohit laria reynolds jonathan tow ben wang samuel weinbach 1 gpt neox _docgpt_neox_japanese abeja released shinya otani takayoshi makabe anuj arora kyo hattori 1 gpt2_docgpt2 openai released paper language model unsupervised multitask  alec radford jeffrey wu rewon child david luan dario amodei ilya sutskever 1 _docgptj eleutherai released repository  ben wang aran komatsuzaki 1 gptsw3_docgptsw3 aisweden released paper lesson learned gptsw3 building first largescale generative language model 2022pdf2022lrec1376pdf ariel ekgren amaru cuba gyllensten evangelia gogoulou alice heiman severine verlinden joey ohman fredrik carlsson magnus sahlgren 1 _docgpt_bigcode bigcode released paper santacoder dont reach 230103988 loubna ben allal raymond li denis kocetkov chenghao mou christopher akiki carlos munoz ferrandis niklas muennighoff mayank mishra alex gu manan dey logesh kumar umapathi carolyn jane anderson yangtian zi joel lamy poirier hailey schoelkopf sergey troshin dmitry abulkhanov manuel romero michael lappert francesco de toni bernardo garcia del rio qian liu shamik bose urvashi bhattacharyya terry yue zhuo ian yu paulo villegas marco zocca sourab mangrulkar david lansky huu nguyen danish contractor luis villa jia li dzmitry bahdanau yacine jernite sean hughes daniel fried arjun guha harm de vries leandro von werra 1 _docgptsanjapanese released repository  toshiyuki sakamototanreinama 1 _docgraphormer microsoft released paper transformer really perform bad graph 210605234 chengxuan ying tianle cai shengjie luo shuxin zheng guolin ke di yanming shen tieyan liu 1 _docgroupvit ucsd nvidia released paper groupvit semantic segmentation emerges text 220211094 jiarui xu shalini de mello sifei liu wonmin byeon thomas breuel jan kautz xiaolong wang 1 _dochubert facebook released paper hubert selfsupervised speech representation learning masked prediction hidden 210607447 weining hsu benjamin bolte yaohung hubert tsai kushal lakhotia ruslan salakhutdinov abdelrahman mohamed 1 _docibert berkeley released paper ibert integeronly bert 210101321 sehoon kim amir gholami zhewei yao michael w mahoney kurt keutzer 1 _docimagegpt openai released paper generative pretraining  mark chen alec radford rewon child jeffrey wu heewoo jun david luan ilya sutskever 1 _docinformer beihang university uc berkeley rutgers university sedd company released paper informer beyond efficient transformer long sequence timeseries 201207436 haoyi zhou shanghang zhang jieqi peng shuai zhang jianxin li hui xiong wancai zhang 1 _docjukebox openai released paper jukebox generative model 200500341pdf prafulla dhariwal heewoo jun christine payne jong wook kim alec radford ilya sutskever 1 _doclayoutlm microsoft research asia released paper layoutlm pretraining text layout document image 191213318 yiheng xu minghao li lei cui shaohan huang furu wei ming zhou 1 layoutlmv2_doclayoutlmv2 microsoft research asia released paper layoutlmv2 multimodal pretraining visuallyrich document 201214740 yang xu yiheng xu tengchao lv lei cui furu wei guoxin wang yijuan lu dinei florencio cha zhang wanxiang che min zhang lidong zhou 1 layoutlmv3_doclayoutlmv3 microsoft research asia released paper layoutlmv3 pretraining document ai unified text image 220408387 yupan huang tengchao lv lei cui yutong lu furu wei 1 _doclayoutxlm microsoft research asia released paper layoutxlm multimodal pretraining multilingual visuallyrich document 210408836 yiheng xu tengchao lv lei cui guoxin wang yijuan lu dinei florencio cha zhang furu wei 1 _docled allenai released paper longformer longdocument 200405150 iz beltagy matthew e peter arman cohan 1 _doclevit meta ai released paper levit vision transformer convnets clothing faster 210401136 ben graham alaaeldin elnouby hugo touvron pierre stock armand joulin herve jegou matthijs douze 1 _doclilt south china university technology released paper lilt simple yet effective languageindependent layout transformer structured document 220213669 jiapeng wang lianwen jin kai ding 1 _docllama fair team meta ai released paper llama open efficient foundation language 230213971 hugo touvron thibaut lavril gautier izacard xavier martinet marieanne lachaux timothee lacroix baptiste roziere naman goyal eric hambro faisal azhar aurelien rodriguez armand joulin edouard grave guillaume lample 1 _doclongformer allenai released paper longformer longdocument 200405150 iz beltagy matthew e peter arman cohan 1 longt5_doclongt5 google ai released paper longt5 efficient texttotext transformer long 211207916 mandy guo joshua ainslie david uthus santiago ontanon jianmo ni yunhsuan sung yinfei yang 1 _docluke studio ousia released paper luke deep contextualized entity representation entityaware 201001057 ikuya yamada akari asai hiroyuki shindo hideaki takeda yuji matsumoto 1 _doclxmert unc chapel hill released paper lxmert learning crossmodality encoder representation transformer opendomain question 190807490 hao tan mohit bansal 1 _docmctct facebook released paper pseudolabeling massively multilingual speech 211100161 loren lugosch tatiana likhomanenko gabriel synnaeve ronan collobert 1 m2m100_docm2m_100 facebook released paper beyond englishcentric multilingual machine 201011125 angela fan shruti bhosale holger schwenk zhiyi ahmed elkishky siddharth goyal mandeep baines onur celebi guillaume wenzek vishrav chaudhary naman goyal tom birch vitaliy liptchinsky sergey edunov edouard grave michael auli armand joulin 1 _docmarian machine translation model trained using  data jorg tiedemann marian  developed microsoft translator team 1 _docmarkuplm microsoft research asia released paper markuplm pretraining text markup language visuallyrich document 211008518 junlong li yiheng xu lei cui furu wei 1 mask2_docmask2former fair uiuc released paper maskedattention mask transformer universal image 211201527 bowen cheng ishan misra alexander g schwing alexander kirillov rohit girdhar 1 _docmaskformer meta uiuc released paper perpixel classification need semantic 210706278 bowen cheng alexander g schwing alexander kirillov 1 _docmatcha google ai released paper matcha enhancing visual language pretraining math reasoning chart 221209662 fangyu liu francesco piccinno syrine krichene chenxi pang kenton lee mandar joshi yasemin altun nigel collier julian martin eisenschlos 1 _docmbart facebook released paper multilingual denoising pretraining neural machine 200108210 yinhan liu jiatao gu naman goyal xian li sergey edunov marjan ghazvininejad mike lewis luke zettlemoyer 1 mbart50_docmbart facebook released paper multilingual translation extensible multilingual pretraining 200800401 yuqing tang chau tran xian li pengjen chen naman goyal vishrav chaudhary jiatao gu angela fan 1 _docmega facebook released paper mega moving average equipped gated 220910655 xuezhe chunting zhou xiang kong junxian liangke gui graham neubig jonathan may luke zettlemoyer 1 _docmegatronbert nvidia released paper megatronlm training multibillion parameter language model using model 190908053 mohammad shoeybi mostofa patwary raul puri patrick legresley jared casper bryan catanzaro 1 megatrongpt2_docmegatron_gpt2 nvidia released paper megatronlm training multibillion parameter language model using model 190908053 mohammad shoeybi mostofa patwary raul puri patrick legresley jared casper bryan catanzaro 1 _docmgpstr alibaba research released paper multigranularity prediction scene text 220903592 peng wang cheng da cong yao 1 _docmluke studio ousia released paper mluke power entity representation multilingual pretrained language 211008151 ryokan ri ikuya yamada yoshimasa tsuruoka 1 _docmobilebert cmugoogle brain released paper mobilebert compact taskagnostic bert resourcelimited 200402984 zhiqing sun hongkun yu xiaodan song renjie liu yiming yang denny zhou 1 mobilenetv1_docmobilenet_v1 google inc released paper mobilenets efficient convolutional neural network mobile vision 170404861 andrew g howard menglong zhu bo chen dmitry kalenichenko weijun wang tobias weyand marco andreetto hartwig adam 1 mobilenetv2_docmobilenet_v2 google inc released paper mobilenetv2 inverted residual linear 180104381 mark sandler andrew howard menglong zhu andrey zhmoginov liangchieh chen 1 _docmobilevit apple released paper mobilevit lightweight generalpurpose mobilefriendly vision 211002178 sachin mehta mohammad rastegari 1 _docmpnet microsoft research released paper mpnet masked permuted pretraining language 200409297 kaitao song xu tan tao qin jianfeng lu tieyan liu 1 mt5_docmt5 google ai released paper mt5 massively multilingual pretrained texttotext 201011934 linting xue noah constant adam robert mihir kale ramus alrfou aditya siddhant aditya barua colin raffel 1 _docmvp ruc ai box released paper mvp multitask supervised pretraining natural language 220612131 tianyi tang junyi li wayne xin zhao jirong wen 1 _docnat shi lab released paper neighborhood attention 220407143 ali hassani steven walton jiachen li shen li humphrey shi 1 _docnezha huawei noah ark lab released paper nezha neural contextualized representation chinese language 190900204 junqiu wei xiaozhe ren xiaoguang li wenyong huang yi liao yasheng wang jiashu lin xin jiang xiao chen qun liu 1 _docnllb meta released paper language left behind scaling humancentered machine 220704672 nllb team 1 _docnllbmoe meta released paper language left behind scaling humancentered machine 220704672 nllb team 1 _docnystromformer university wisconsin madison released paper nystromformer nystrombased algorithm approximating 210203902 yunyang xiong zhanpeng zeng rudrasis chakraborty mingxing tan glenn fung yin li vikas singh 1 _doconeformer shi lab released paper oneformer one transformer rule universal image 221106220 jitesh jain jiachen li mangtik chiu ali hassani nikita orlov humphrey shi 1 _docopenllama  released  1 _docopt meta ai released paper opt open pretrained transformer language 220501068 susan zhang stephen roller naman goyal mikel artetxe moya chen shuohui chen et al 1 _docowlvit google ai released paper simple openvocabulary object detection vision 220506230 matthias minderer alexey gritsenko austin stone maxim neumann dirk weissenborn alexey dosovitskiy aravindh mahendran anurag arnab mostafa dehghani zhuoran shen xiao wang xiaohua zhai thomas kipf neil houlsby 1 _docpegasus google released paper pegasus pretraining extracted gapsentences abstractive 191208777 jingqing zhang yao zhao mohammad saleh peter j liu 1 _docpegasus_x google released paper investigating efficiently extending transformer long input 220804347 jason phang yao zhao peter j liu 1 perceiver _docperceiver deepmind released paper perceiver io general architecture structured input 210714795 andrew jaegle sebastian borgeaud jeanbaptiste alayrac carl doersch catalin ionescu david ding skanda koppula daniel zoran andrew brock evan shelhamer olivier henaff matthew botvinick andrew zisserman oriol vinyals joao carreira 1 _docphobert vinai research released paper phobert pretrained language model 2020findingsemnlp92 dat quoc nguyen anh tuan nguyen 1 pix2_docpix2struct google released paper pix2struct screenshot parsing pretraining visual language 221003347 kenton lee mandar joshi iulia turc hexiang hu fangyu liu julian eisenschlos urvashi khandelwal peter shaw mingwei chang kristina toutanova 1 _docplbart ucla nlp released paper unified pretraining program understanding 210306333 wasi uddin ahmad saikat chakraborty baishakhi ray kaiwei chang 1 _docpoolformer sea ai lab released paper metaformer actually need 211111418 yu weihao luo mi zhou pan si chenyang zhou yichen wang xinchao feng jiashi yan shuicheng 1 _docprophetnet microsoft research released paper prophetnet predicting future ngram sequencetosequence 200104063 yu yan weizhen qi yeyun gong dayiheng liu nan duan jiusheng chen ruofei zhang ming zhou 1 _docqdqbert nvidia released paper integer quantization deep learning inference principle empirical 200409602 hao wu patrick judd xiaojie zhang mikhail isaev paulius micikevicius 1 _docrag facebook released paper retrievalaugmented generation knowledgeintensive nlp 200511401 patrick lewis ethan perez aleksandara piktus fabio petroni vladimir karpukhin naman goyal heinrich kuttler mike lewis wentau yih tim rocktaschel sebastian riedel douwe kiela 1 _docrealmhtml google research released paper realm retrievalaugmented language model 200208909 kelvin guu kenton lee zora tung panupong pasupat mingwei chang 1 _docreformer google research released paper reformer efficient 200104451 nikita kitaev ukasz kaiser anselm levskaya 1 _docregnet meta platform released paper designing network design 200313678 ilija radosavovic raj prateek kosaraju ross girshick kaiming piotr dollar 1 _docrembert google research released paper rethinking embedding coupling pretrained language 201012821 hyung chung thibault fevry henry tsai johnson sebastian ruder 1 _docresnet microsoft research released paper deep residual learning image 151203385 kaiming xiangyu zhang shaoqing ren jian sun 1 _docroberta facebook released together paper roberta robustly optimized bert pretraining 190711692 yinhan liu myle ott naman goyal jingfei du mandar joshi danqi chen omer levy mike lewis luke zettlemoyer veselin stoyanov 1 _docrobertaprelayernorm facebook released paper fairseq fast extensible toolkit sequence 190401038 myle ott sergey edunov alexei baevski angela fan sam gross nathan ng david grangier michael auli 1 _docroc_bert wechatai released paper rocbert robust chinese bert multimodal contrastive 2022acllong65pdf huisu weiweishi xiaoyushen xiaozhou tuoji jiaruifang jiezhou 1 _docroformer zhuiyitechnology released together paper roformer enhanced transformer rotary position 210409864 jianlin su yu lu shengfeng pan bo wen yunfeng liu 1 _docrwkv bo peng released  bo peng 1 _docsegformer nvidia released paper segformer simple efficient design semantic segmentation 210515203 enze xie wenhai wang zhiding yu anima anandkumar jose alvarez ping luo 1 segment _docsam meta ai released paper segment 230402643v1pdf alexander kirillov eric mintun nikhila ravi hanzi mao chloe rolland laura gustafson tete xiao spencer whitehead alex berg wanyen lo piotr dollar ross girshick 1 _docsew asapp released paper performanceefficiency tradeoff unsupervised pretraining speech 210906870 felix wu kwangyoun kim jing pan kyu han kilian q weinberger yoav artzi 1 _docsew_d asapp released paper performanceefficiency tradeoff unsupervised pretraining speech 210906870 felix wu kwangyoun kim jing pan kyu han kilian q weinberger yoav artzi 1 speecht5_docspeecht5 microsoft research released paper speecht5 unifiedmodal encoderdecoder pretraining spoken language 211007205 junyi ao rui wang long zhou chengyi wang shuo ren yu wu shujie liu tom ko qing li yu zhang zhihua wei yao qian jinyu li furu wei 1 _docspeech_to_text facebook released together paper fairseq s2t fast speechtotext modeling 201005171 changhan wang yun tang xutai anne wu dmytro okhonko juan pino 1 speechtotexttransformer2_docspeech_to_text_2 facebook released together paper largescale self semisupervised learning speech 210406678 changhan wang anne wu juan pino alexei baevski michael auli alexis conneau 1 _docsplinter tel aviv university released together paper fewshot question answering pretraining span 210100438 ori ram yuval kirstain jonathan berant amir globerson omer levy 1 _docsqueezebert berkeley released paper squeezebert computer vision teach nlp efficient neural 200611316 forrest n iandola albert e shaw ravi krishna kurt w keutzer 1 _docswiftformer mbzuai released paper swiftformer efficient additive attention transformerbased realtime mobile vision 230315446 abdelrahman shaker muhammad maaz hanoona rasheed salman khan minghsuan yang fahad shahbaz khan 1 swin _docswin microsoft released paper swin transformer hierarchical vision transformer using shifted 210314030 ze liu yutong lin yue cao han hu yixuan wei zheng zhang stephen lin baining guo 1 swin transformer v2_docswinv2 microsoft released paper swin transformer v2 scaling capacity 211109883 ze liu han hu yutong lin zhuliang yao zhenda xie yixuan wei jia ning yue cao zheng zhang li dong furu wei baining guo 1 swin2_docswin2sr university wurzburg released paper swin2sr swinv2 transformer compressed image superresolution 220911345 marcos v conde uijin choi maxime burchi radu timofte 1 _docswitch_transformers google released paper switch transformer scaling trillion parameter model simple efficient 210103961 william fedus barret zoph noam shazeer 1 t5_doct5 google ai released paper exploring limit transfer learning unified texttotext 191010683 colin raffel noam shazeer adam robert katherine lee sharan narang michael matena yanqi zhou wei li peter j liu 1 t5v11_doct5v11 google ai released repository _checkpointsmdt511 colin raffel noam shazeer adam robert katherine lee sharan narang michael matena yanqi zhou wei li peter j liu 1 table _doctabletransformer microsoft research released paper pubtables1m towards comprehensive table extraction unstructured 211000061 brandon smock rohith pesala robin abraham 1 _doctapas google ai released paper tapa weakly supervised table parsing via 200402349 jonathan herzig pawe krzysztof nowak thomas muller francesco piccinno julian martin eisenschlos 1 _doctapex microsoft research released paper tapex table pretraining via learning neural sql 210707653 qian liu bei chen jiaqi guo morteza ziyadi zeqi lin weizhu chen jianguang lou 1 time series _doctime_series_transformer huggingface 1 _doctimesformer facebook released paper spacetime attention need video 210205095 gedas bertasius heng wang lorenzo torresani 1 trajectory _doctrajectory_transformers university california berkeley released paper offline reinforcement learning one big sequence modeling 210602039 michael janner qiyang li sergey levine 1 _doctransfoxl googlecmu released paper transformerxl attentive language model beyond fixedlength 190102860 zihang dai zhilin yang yiming yang jaime carbonell quoc v le ruslan salakhutdinov 1 _doctrocr microsoft released together paper trocr transformerbased optical character recognition pretrained 210910282 minghao li tengchao lv lei cui yijuan lu dinei florencio cha zhang zhoujun li furu wei 1 _doctvlt unc chapel hill released paper tvlt textless visionlanguage 220914156 zineng tang jaemin cho yixin nie mohit bansal 1 ul2_docul2 google research released paper unifying language learning 220505131v1 yi tay mostafa dehghani vinh q tran xavier garcia dara bahri tal schuster huaixiu steven zheng neil houlsby donald metzler 1 _docunispeech microsoft research released paper unispeech unified speech representation learning labeled unlabeled 210107597 chengyi wang yu wu yao qian kenichi kumatani shujie liu furu wei michael zeng xuedong huang 1 _docunispeechsat microsoft research released paper unispeechsat universal speech representation learning speaker aware 211005752 sanyuan chen yu wu chengyi wang zhengyang chen zhuo chen shujie liu jian wu yao qian furu wei jinyu li xiangzhan yu 1 _docupernet peking university released paper unified perceptual parsing scene 180710221 tete xiao yingcheng liu bolei zhou yuning jiang jian sun 1 _docvan tsinghua university nankai university released paper visual attention 220209741 menghao guo chengze lu zhengning liu mingming cheng shimin hu 1 _docvideomae multimedia computing group nanjing university released paper videomae masked autoencoders dataefficient learner selfsupervised video 220312602 zhan tong yibing song jue wang limin wang 1 _docvilt naver ai labkakao enterprisekakao brain released paper vilt visionandlanguage transformer without convolution region 210203334 wonjae kim bokyung son ildoo kim 1 vision transformer _docvit google ai released paper image worth 16x16 word transformer image recognition 201011929 alexey dosovitskiy lucas beyer alexander kolesnikov dirk weissenborn xiaohua zhai thomas unterthiner mostafa dehghani matthias minderer georg heigold sylvain gelly jakob uszkoreit neil houlsby 1 _docvisual_bert ucla nlp released paper visualbert simple performant baseline vision 190803557 liunian harold li mark yatskar da yin chojui hsieh kaiwei chang 1 vit _docvit_hybrid google ai released paper image worth 16x16 word transformer image recognition 201011929 alexey dosovitskiy lucas beyer alexander kolesnikov dirk weissenborn xiaohua zhai thomas unterthiner mostafa dehghani matthias minderer georg heigold sylvain gelly jakob uszkoreit neil houlsby 1 _docvit_mae meta ai released paper masked autoencoders scalable vision 211106377 kaiming xinlei chen saining xie yanghao li piotr dollar ross girshick 1 _docvit_msn meta ai released paper masked siamese network labelefficient 220407141 mahmoud assran mathilde caron ishan misra piotr bojanowski florian bordes pascal vincent armand joulin michael rabbat nicolas ballas 1 wav2vec2_docwav2vec2 facebook ai released paper wav2vec 20 framework selfsupervised learning speech 200611477 alexei baevski henry zhou abdelrahman mohamed michael auli 1 wav2vec2_docwav2vec2conformer facebook ai released paper fairseq s2t fast speechtotext modeling 201005171 changhan wang yun tang xutai anne wu sravya popuri dmytro okhonko juan pino 1 wav2vec2_docwav2vec2_phoneme facebook ai released paper simple effective zeroshot crosslingual phoneme 210911680 qiantong xu alexei baevski michael auli 1 _docwavlm microsoft research released paper wavlm largescale selfsupervised pretraining full stack speech 211013900 sanyuan chen chengyi wang zhengyang chen yu wu shujie liu zhuo chen jinyu li naoyuki kanda takuya yoshioka xiong xiao jian wu long zhou shuo ren yanmin qian yao qian jian wu michael zeng furu wei 1 _docwhisper openai released paper robust speech recognition via largescale weak  alec radford jong wook kim tao xu greg brockman christine mcleavey ilya sutskever 1 _docxclip microsoft research released paper expanding languageimage pretrained model general video 220802816 bolin ni houwen peng minghao chen songyang zhang gaofeng meng jianlong fu shiming xiang haibin ling 1 _docxmod meta ai released paper lifting curse multilinguality pretraining modular 1018653v12022naaclmain255 jonas pfeiffer naman goyal xi lin xian li james cross sebastian riedel mikel artetxe 1 _docxglm facebook ai released paper fewshot learning multilingual language 211210668 xi victoria lin todor mihaylov mikel artetxe tianlu wang shuohui chen daniel simig myle ott naman goyal shruti bhosale jingfei du ramakanth pasunuru sam shleifer punit singh koura vishrav chaudhary brian ohoro jeff wang luke zettlemoyer zornitsa kozareva mona diab veselin stoyanov xian li 1 _docxlm facebook released together paper crosslingual language model 190107291 guillaume lample alexis conneau 1 _docxlmprophetnet microsoft research released paper prophetnet predicting future ngram sequencetosequence 200104063 yu yan weizhen qi yeyun gong dayiheng liu nan duan jiusheng chen ruofei zhang ming zhou 1 _docxlmroberta facebook ai released together paper unsupervised crosslingual representation learning 191102116 alexis conneau kartikay khandelwal naman goyal vishrav chaudhary guillaume wenzek francisco guzman edouard grave myle ott luke zettlemoyer veselin stoyanov 1 _docxlmrobertaxl facebook ai released together paper largerscale transformer multilingual masked language 210500572 naman goyal jingfei du myle ott giri anantharaman alexis conneau 1 _docxlmv meta ai released paper xlmv overcoming vocabulary bottleneck multilingual masked language 230110472 davis liang hilum gonen yuning mao rui hou naman goyal marjan ghazvininejad luke zettlemoyer madian khabsa 1 _docxlnet googlecmu released paper xlnet generalized autoregressive pretraining language 190608237 zhilin yang zihang dai yiming yang jaime carbonell ruslan salakhutdinov quoc v le 1 _docxls_r facebook ai released paper xlsr selfsupervised crosslingual speech representation learning 211109296 arun babu changhan wang andros tjandra kushal lakhotia qiantong xu naman goyal kritika singh patrick von platen yatharth saraf juan pino alexei baevski alexis conneau michael auli 1 xlsrwav2vec2_docxlsr_wav2vec2 facebook ai released paper unsupervised crosslingual representation learning speech 200613979 alexis conneau alexei baevski ronan collobert abdelrahman mohamed michael auli 1 _docyolos huazhong university science technology released paper look one sequence rethinking transformer vision object 210600666 yuxin fang bencheng liao xinggang wang jiemin fang jiyang qi rui wu jianwei niu wenyu liu 1 _docyoso university wisconsin madison released paper sample almost linear cost selfattention via bernoulli 211109714 zhanpeng zeng yunyang xiong sathya n ravi shailesh acharya glenn fung vikas singh 1 want contribute new model added detailed guide template guide process adding new model find templatestemplates folder repository sure check contributing guidelinescontributingmd contact maintainer open issue collect feedback starting pr check model ha implementation flax pytorch tensorflow ha associated tokenizer backed tokenizers library refer  implementation tested several datasets see example script match performance original implementation find detail performance example section  learn section description  full api documentation tutorial task _summary task supported transformer preprocessing  using tokenizer class prepare data model training  using model provided transformer pytorchtensorflow training loop trainer api quick tour finetuningusage  example script finetuning model wide range task model sharing _sharing upload share finetuned model community  migrate transformer pytorchtransformers pytorchpretrainedbert citation 2020emnlpdemos6 cite transformer library bibtex inproceedingswolfetal2020transformers title transformer stateoftheart natural language processing author thomas wolf lysandre debut victor sanh julien chaumond clement delangue anthony moi pierric cistac tim rault remi louf morgan funtowicz joe davison sam shleifer patrick von platen clara yacine jernite julien plu canwen xu teven le scao sylvain gugger mariama drame quentin lhoest alexander rush booktitle proceeding 2020 conference empirical method natural language processing system demonstration month oct year 2020 address online publisher association computational linguistics url 2020emnlpdemos6 page 3845'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'[a-z]*http[a-z]*', '', data.iloc[0]['cleaned_readme_contents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0cb12b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 500)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "255b229a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_http = [re.sub(r'[a-z]*http[a-z]*', '', data.iloc[i]['cleaned_readme_contents']) \n",
    "#            for i in range(len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3b2e1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.cleaned_readme_contents.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2ee59ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "      <th>cleaned_readme_contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>1712n/yachay-public</td>\n",
       "      <td>HTML</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>usyiyi/nlp-py-2e-zh</td>\n",
       "      <td>HTML</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>mneedham/neo4j-himym</td>\n",
       "      <td>HTML</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>mwt/econ-ipsum</td>\n",
       "      <td>HTML</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>johnoseni1/NLP-video-player</td>\n",
       "      <td>HTML</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>ADHIKSHA/Essay-Grading-IELTS</td>\n",
       "      <td>HTML</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>MichiganNLP/textgraphs</td>\n",
       "      <td>HTML</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             repo language readme_contents  \\\n",
       "322           1712n/yachay-public     HTML             NaN   \n",
       "330           usyiyi/nlp-py-2e-zh     HTML             NaN   \n",
       "338          mneedham/neo4j-himym     HTML             NaN   \n",
       "374                mwt/econ-ipsum     HTML             NaN   \n",
       "435   johnoseni1/NLP-video-player     HTML             NaN   \n",
       "463  ADHIKSHA/Essay-Grading-IELTS     HTML             NaN   \n",
       "474        MichiganNLP/textgraphs     HTML             NaN   \n",
       "\n",
       "    cleaned_readme_contents  \n",
       "322                     NaN  \n",
       "330                     NaN  \n",
       "338                     NaN  \n",
       "374                     NaN  \n",
       "435                     NaN  \n",
       "463                     NaN  \n",
       "474                     NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.cleaned_readme_contents.isna() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8be8e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.cleaned_readme_contents.isna() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46944b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(493, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1e2dfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_http = [re.sub(r'[a-z]*http[a-z]*', '', data.iloc[i]['cleaned_readme_contents']) \n",
    "           for i in range(len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24bf2b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'copyright 2020 huggingface team right reserved licensed apache license version 20 license may use file except compliance license may obtain copy license 20 unless required applicable law agreed writing software distributed license distributed basis without warranty condition kind either express implied see license specific language governing permission limitation license p aligncenter picture source mediapreferscolorscheme dark  source mediapreferscolorscheme light  img althugging face transformer library  width352 height59 stylemaxwidth 100 picture br br p p aligncenter  img altbuild   img altgithub   img altdocumentation _colorreddown_messageofflineup_messageonline  img altgithub release  _of_conductmd img altcontributor covenant 20covenantv2020adoptedff69b4svg 155220641img 155220641svg altdoia p h4 aligncenter p benglishb _zhhansmda _zhhantmda _komda _esmdespanola _jamda _hdmda p h4 h3 aligncenter pstateoftheart machine learning jax pytorch tensorflowp h3 h3 aligncenter  _bannerpnga h3 transformer provides thousand pretrained model perform task different modality text vision audio model applied text task like text classification information extraction question answering summarization translation text generation 100 language image task like image classification object detection segmentation audio task like speech recognition audio classification transformer model also perform task several modality combined table question answering optical character recognition information extraction scanned document video classification visual question answering transformer provides apis quickly download use pretrained model given text finetune datasets share community model  time module defining architecture fully standalone modified enable quick research experiment transformer backed three popular deep learning library    seamless integration straightforward train model one loading inference online demo test model directly page model  also offer private model hosting versioning inference  public private model example natural language processing masked word completion 5bmask5doffrance name entity recognition 03englishtextmynameissarahandiliveinlondoncity text generation gpt22textalongtimeago2c natural language inference  summarization 324metres2812c063ft29tall2caboutthesameheightasan81storeybuilding2candthetalleststructureinparisitsbaseissquare2cmeasuring125metres28410ft29oneachsideduringitsconstruction2ctheeiffeltowersurpassedthewashingtonmonumenttobecomethetallestmanmadestructureintheworld2catitleitheldfor41yearsuntilthechryslerbuildinginnewyorkcitywasfinishedin1930itwasthefirststructuretoreachaheightof300metresduetotheadditionofabroadcastingaerialatthetopofthetowerin19572citisnowtallerthanthechryslerbuildingby52metres2817ft29excludingtransmitters2ctheeiffeltoweristhesecondtallestfreestandingstructureinfranceafterthemillauviaduct question answering 3fcontexttheamazonrainforest28portuguese3aflorestaamazc3b4nicaoramazc3b4nia3bspanish3aselvaamazc3b3nica2camazonc3adaorusuallyamazonia3bfrench3aforc3aatamazonienne3bdutch3aamazoneregenwoud292calsoknowninenglishasamazoniaortheamazonjungle2cisamoistbroadleafforestthatcoversmostoftheamazonbasinofsouthamericathisbasinencompasses72c0002c000squarekilometres2822c7002c000sqmi292cofwhich52c5002c000squarekilometres2822c1002c000sqmi29arecoveredbytherainforestthisregionincludesterritorybelongingtoninenationsthemajorityoftheforestiscontainedwithinbrazil2cwith6025oftherainforest2cfollowedbyperuwith13252ccolombiawith10252candwithminoramountsinvenezuela2cecuador2cbolivia2cguyana2csurinameandfrenchguianastatesordepartmentsinfournationscontain22amazonas22intheirnamestheamazonrepresentsoverhalfoftheplanet27sremainingrainforests2candcomprisesthelargestandmostbiodiversetractoftropicalrainforestintheworld2cwithanestimated390billionindividualtreesdividedinto162c000species translation t55basetextmynameiswolfgangandiliveinberlin computer vision image classification 16224 object detection 50 semantic segmentation 0finetunedade512512 panoptic segmentation  depth estimation _docdpt video classification _docvideomae universal segmentation _ade20k_dinat_large audio automatic speech recognition wav2vec22vec2base960h keyword spotting wav2vec22vec2basesuperbks audio classification audio spectrogram 101004593 multimodal task table question answering  visual question answering 32finetunedvqa zeroshot image classification 14 document question answering  zeroshot video classification _docxclip write  built hugging face team official demo repos text generation capability looking custom support hugging face team target_blank  img althuggingface expert acceleration program  stylemaxwidth 600px border 1px solid eee borderradius 4px boxshadow 0 1px 2px 0 rgba0 0 0 005 abr quick tour immediately use model given input text image audio provide pipeline api pipeline group together pretrained model preprocessing wa used model training quickly use pipeline classify positive versus negative text transformer import pipeline allocate pipeline sentimentanalysis classifier pipelinesentimentanalysis classifierwe happy introduce pipeline transformer repository label positive score 09996980428695679 second line code downloads cache pretrained model used pipeline third evaluates given text answer positive confidence 9997 many task pretrained pipeline ready go nlp also computer vision speech example easily extract detected object image import request pil import image transformer import pipeline download image cute cat url _samplepng image_data requestsgeturl streamtrueraw image imageopenimage_data allocate pipeline object detection object_detector pipelineobjectdetection object_detectorimage score 09982201457023621 label remote box xmin 40 ymin 70 xmax 175 ymax 117 score 09960021376609802 label remote box xmin 333 ymin 72 xmax 368 ymax 187 score 09954745173454285 label couch box xmin 0 ymin 1 xmax 639 ymax 473 score 09988006353378296 label cat box xmin 13 ymin 52 xmax 314 ymax 470 score 09986783862113953 label cat box xmin 345 ymin 23 xmax 640 ymax 368 get list object detected image box surrounding object confidence score original image left prediction displayed right h3 aligncenter aimg _samplepng width400a aimg _sample_post_processedpng width400a h3 learn task supported pipeline api _summary addition pipeline download use pretrained model given task take three line code pytorch version transformer import autotokenizer automodel tokenizer autotokenizerfrom_pretrainedbertbaseuncased model automodelfrom_pretrainedbertbaseuncased input tokenizerhello world return_tensorspt output modelinputs equivalent code tensorflow transformer import autotokenizer tfautomodel tokenizer autotokenizerfrom_pretrainedbertbaseuncased model tfautomodelfrom_pretrainedbertbaseuncased input tokenizerhello world return_tensorstf output modelinputs tokenizer responsible preprocessing pretrained model expects called directly single string example list output dictionary use downstream code simply directly pas model using argument unpacking operator model regular pytorch  tensorflow _docfkerasmodel depending backend use usual  explains integrate model classic pytorch tensorflow training loop use trainer api quickly finetune new dataset use transformer 1 easytouse stateoftheart model high performance natural language understanding generation computer vision audio task low barrier entry educator practitioner userfacing abstraction three class learn unified api using pretrained model 1 lower compute cost smaller carbon footprint researcher share trained model instead always retraining practitioner reduce compute time production cost dozen architecture 60000 pretrained model across modality 1 choose right framework every part model lifetime train stateoftheart model 3 line code move single model tf20pytorchjax framework seamlessly pick right framework training evaluation production 1 easily customize model example need provide example architecture reproduce result published original author model internals exposed consistently possible model file used independently library quick experiment shouldnt use transformer library modular toolbox building block neural net code model file refactored additional abstraction purpose researcher quickly iterate model without diving additional abstractionsfiles training api intended work model optimized work model provided library generic machine learning loop use another library possibly  strive present many use case possible script example  example expected wont work outofthe box specific problem required change line code adapt need installation pip repository tested 36 flax 032 pytorch 131 tensorflow 23 install transformer virtual 3libraryvenvhtml youre unfamiliar virtual environment check user  first create virtual environment version youre going use activate need install least one flax pytorch tensorflow please refer tensorflow installation  pytorch installation  andor   installation page regarding specific installation command platform one backends ha installed transformer installed using pip follows bash pip install transformer youd like play example need bleeding edge code cant wait new release must install library  conda since transformer version v400 conda channel huggingface transformer installed using conda follows shell script conda install c huggingface transformer follow installation page flax pytorch tensorflow see install conda _note_ window may prompted activate developer mode order benefit caching option please let u know _hubissues1062 model architecture model  provided transformer seamlessly integrated huggingfaceco model  uploaded directly   current number checkpoint  transformer currently provides following architecture see _summary highlevel summary 1 _docalbert google research toyota technological institute chicago released paper albert lite bert selfsupervised learning language 190911942 zhenzhong lan mingda chen sebastian goodman kevin gimpel piyush sharma radu soricut 1 _docalign google research released paper scaling visual visionlanguage representation learning noisy text 210205918 chao jia yinfei yang ye xia yiting chen zarana parekh hieu pham quoc v le yunhsuan sung zhen li tom duerig 1 _docaltclip baai released paper altclip altering language encoder clip extended language 221106679 chen zhongzhi liu guang zhang bowen ye fulong yang qinghong wu ledell 1 audio spectrogram _docaudiospectrogramtransformer mit released paper ast audio spectrogram 210401778 yuan gong yuan chung james glass 1 _docbart facebook released paper bart denoising sequencetosequence pretraining natural language generation translation 191013461 mike lewis yinhan liu naman goyal marjan ghazvininejad abdelrahman mohamed omer levy f stoyanov luke zettlemoyer 1 _docbarthez ecole polytechnique released paper barthez skilled pretrained french sequencetosequence 201012321 moussa kamal eddine antoine jp tixier michalis vazirgiannis 1 _docbartpho vinai research released paper bartpho pretrained sequencetosequence model 210909701 nguyen luong tran duong minh le dat quoc nguyen 1 _docbeit microsoft released paper beit bert pretraining image 210608254 hangbo bao li dong furu wei 1 _docbert google released paper bert pretraining deep bidirectional transformer language 181004805 jacob devlin mingwei chang kenton lee kristina toutanova 1 bert sequence _docbertgeneration google released paper leveraging pretrained checkpoint sequence generation 190712461 sascha rothe shashi narayan aliaksei severyn 1 _docbertweet vinai research released paper bertweet pretrained language model english 2020emnlpdemos2 dat quoc nguyen thanh vu anh tuan nguyen 1 _docbigbird_pegasus google research released paper big bird transformer longer 200714062 manzil zaheer guru guruganesh avinava dubey joshua ainslie chris alberti santiago ontanon philip pham anirudh ravula qifan wang li yang amr ahmed 1 _docbig_bird google research released paper big bird transformer longer 200714062 manzil zaheer guru guruganesh avinava dubey joshua ainslie chris alberti santiago ontanon philip pham anirudh ravula qifan wang li yang amr ahmed 1 _docbiogpt microsoft research ai4science released paper biogpt generative pretrained transformer biomedical text generation 101093bibbbac4096713511guestaccesskeya66d9b5d4f834017bb52405815c907b9 renqian luo liai sun yingce xia tao qin sheng zhang hoifung poon tieyan liu 1 _docbit google ai released paper big transfer bit general visual representation 191211370 alexander kolesnikov lucas beyer xiaohua zhai joan puigcerver jessica yung sylvain gelly neil houlsby 1 _docblenderbot facebook released paper recipe building opendomain 200413637 stephen roller emily dinan naman goyal da ju mary williamson yinhan liu jing xu myle ott kurt shuster eric smith ylan boureau jason weston 1 _docblenderbotsmall facebook released paper recipe building opendomain 200413637 stephen roller emily dinan naman goyal da ju mary williamson yinhan liu jing xu myle ott kurt shuster eric smith ylan boureau jason weston 1 _docblip salesforce released paper blip bootstrapping languageimage pretraining unified visionlanguage understanding 220112086 junnan li dongxu li caiming xiong steven hoi 1 blip2_docblip2 salesforce released paper blip2 bootstrapping languageimage pretraining frozen image encoders large language 230112597 junnan li dongxu li silvio savarese steven hoi 1 _docbloom bigscience workshop released bigscience  1 _docbort alexa released paper optimal subarchitecture extraction 201010499 adrian de wynter daniel j perry 1 _docbridgetower harbin institute technologymicrosoft research asiaintel lab released paper bridgetower building bridge encoders visionlanguage representation 220608657 xiao xu chenfei wu shachar rosenman vasudev lal wanxiang che nan duan 1 byt5_docbyt5 google research released paper byt5 towards tokenfree future pretrained bytetobyte 210513626 linting xue aditya barua noah constant ramus alrfou sharan narang mihir kale adam robert colin raffel 1 _doccamembert inriafacebooksorbonne released paper camembert tasty french language 191103894 louis martin benjamin muller pedro javier ortiz suarez yoann dupont laurent romary eric villemonte de la clergerie djame seddah benoit sagot 1 _doccanine google research released paper canine pretraining efficient tokenizationfree encoder language 210306874 jonathan h clark dan garrette iulia turc john wieting 1 _docchinese_clip ofasys released paper chinese clip contrastive visionlanguage pretraining 221101335 yang junshu pan junyang lin rui men yichang zhang jingren zhou chang zhou 1 _docclap laionai released paper largescale contrastive languageaudio pretraining feature fusion keywordtocaption 221106687 yusong wu ke chen tianyu zhang yuchen hui taylor bergkirkpatrick shlomo dubnov 1 _docclip openai released paper learning transferable visual model natural language 210300020 alec radford jong wook kim chris hallacy aditya ramesh gabriel goh sandhini agarwal girish sastry amanda askell pamela mishkin jack clark gretchen krueger ilya sutskever 1 _docclipseg university gottingen released paper image segmentation using text image 211210003 timo luddecke alexander ecker 1 _doccodegen salesforce released paper conversational paradigm program 220313474 erik nijkamp bo pang hiroaki hayashi lifu tu huan wang yingbo zhou silvio savarese caiming xiong 1 conditional _docconditional_detr microsoft research asia released paper conditional detr fast training 210806152 depu meng xiaokang chen zejia fan gang zeng houqiang li yuhui yuan lei sun jingdong wang 1 _docconvbert yitutech released paper convbert improving bert spanbased dynamic 200802496 zihang jiang weihao yu daquan zhou yunpeng chen jiashi feng shuicheng yan 1 _docconvnext facebook ai released paper convnet 2020220103545 zhuang liu hanzi mao chaoyuan wu christoph feichtenhofer trevor darrell saining xie 1 convnextv2_docconvnextv2 facebook ai released paper convnext v2 codesigning scaling convnets masked 230100808 sanghyun woo shoubhik debnath ronghang hu xinlei chen zhuang liu kweon saining xie 1 _doccpm tsinghua university released paper cpm largescale generative chinese pretrained language 201200413 zhengyan zhang xu han hao zhou pei ke yuxian gu deming ye yujia qin yusheng su haozhe ji jian guan fanchao qi xiaozhi wang yanan zheng guoyang zeng huanqi cao shengqi chen daixuan li zhenbo sun zhiyuan liu minlie huang wentao han jie tang juanzi li xiaoyan zhu maosong sun 1 _doccpmant openbmb released  1 _docctrl salesforce released paper ctrl conditional transformer language model controllable 190905858 nitish shirish keskar bryan mccann lav r varshney caiming xiong richard socher 1 _doccvt microsoft released paper cvt introducing convolution vision 210315808 haiping wu bin xiao noel codella mengchen liu xiyang dai lu yuan lei zhang 1 data2_docdata2vec facebook released paper data2vec general framework selfsupervised learning speech vision 220203555 alexei baevski weining hsu qiantong xu arun babu jiatao gu michael auli 1 _docdeberta microsoft released paper deberta decodingenhanced bert disentangled 200603654 pengcheng xiaodong liu jianfeng gao weizhu chen 1 debertav2_docdebertav2 microsoft released paper deberta decodingenhanced bert disentangled 200603654 pengcheng xiaodong liu jianfeng gao weizhu chen 1 decision _docdecision_transformer berkeleyfacebookgoogle released paper decision transformer reinforcement learning via sequence 210601345 lili chen kevin lu aravind rajeswaran kimin lee aditya grover michael laskin pieter abbeel aravind srinivas igor mordatch 1 deformable _docdeformable_detr sensetime research released paper deformable detr deformable transformer endtoend object 201004159 xizhou zhu weijie su lewei lu bin li xiaogang wang jifeng dai 1 _docdeit facebook released paper training dataefficient image transformer distillation 201212877 hugo touvron matthieu cord matthijs douze francisco massa alexandre sablayrolles herve jegou 1 _docdeplot google ai released paper deplot oneshot visual language reasoning plottotable 221210505 fangyu liu julian martin eisenschlos francesco piccinno syrine krichene chenxi pang kenton lee mandar joshi wenhu chen nigel collier yasemin altun 1 _docdeta university texas austin released paper nm strike 221206137 jeffrey ouyangzhang jang hyun cho xingyi zhou philipp krahenbuhl 1 _docdetr facebook released paper endtoend object detection 200512872 nicolas carion francisco massa gabriel synnaeve nicolas usunier alexander kirillov sergey zagoruyko 1 _docdialogpt microsoft research released paper dialogpt largescale generative pretraining conversational response 191100536 yizhe zhang siqi sun michel galley yenchun chen chris brockett xiang gao jianfeng gao jingjing liu bill dolan 1 _docdinat shi lab released paper dilated neighborhood attention 220915001 ali hassani humphrey shi 1 _docdistilbert huggingface released together paper distilbert distilled version bert smaller faster cheaper 191001108 victor sanh lysandre debut thomas wolf method ha applied compress gpt2 distilgpt2_projectsdistillation roberta _projectsdistillation multilingual bert _projectsdistillation german version distilbert 1 _docdit microsoft research released paper dit selfsupervised pretraining document image 220302378 junlong li yiheng xu tengchao lv lei cui cha zhang furu wei 1 _docdonut naver released together paper ocrfree document understanding 211115664 geewook kim teakgyu hong moonbin yim jeongyeon nam jinyoung park jinyeong yim wonseok hwang sangdoo yun dongyoon han seunghyun park 1 _docdpr facebook released paper dense passage retrieval opendomain question 200404906 vladimir karpukhin barlas oguz sewon min patrick lewis ledell wu sergey edunov danqi chen wentau yih 1 _docdpt intel lab released paper vision transformer dense 210313413 rene ranftl alexey bochkovskiy vladlen koltun 1 _docefficientformer snap research released paper efficientformer vision transformer 220601191 yanyu li geng yuan yang wen ju hu georgios evangelidis sergey tulyakov yanzhi wang jian ren 1 _docefficientnet google brain released paper efficientnet rethinking model scaling convolutional neural 190511946 mingxing tan quoc v le 1 _docelectra google researchstanford university released paper electra pretraining text encoders discriminator rather 200310555 kevin clark minhthang luong quoc v le christopher manning 1 _docencoderdecoder google research released paper leveraging pretrained checkpoint sequence generation 190712461 sascha rothe shashi narayan aliaksei severyn 1 _docernie baidu released paper ernie enhanced representation knowledge 190409223 yu sun shuohuan wang yukun li shikun feng xuyi chen han zhang xin tian danxiang zhu hao tian hua wu 1 _docernie_m baidu released paper erniem enhanced multilingual representation aligning crosslingual semantics monolingual 201215674 xuan ouyang shuohuan wang chao pang yu sun hao tian hua wu haifeng wang 1 _docesm meta ai transformer protein language model esm1b wa released paper biological structure function emerge scaling unsupervised learning 250 million protein 11815e2016239118 alexander rives joshua meier tom sercu siddharth goyal zeming lin jason liu demi guo myle ott c lawrence zitnick jerry rob fergus esm1v wa released paper language model enable zeroshot prediction effect mutation protein 10110120210709450648 joshua meier roshan rao robert verkuil jason liu tom sercu alexander rives esm2 esmfold released paper language model protein sequence scale evolution enable accurate structure 10110120220720500902 zeming lin halil akin roshan rao brian hie zhongkai zhu wenting lu allan santos costa maryam fazelzarandi tom sercu sal candido alexander rives 1 flant5_docflant5 google ai released repository googleresearcht55xblobmaindocsmodelsmdflant5checkpoints hyung chung le hou shayne longpre barret zoph yi tay william fedus eric li xuezhi wang mostafa dehghani siddhartha brahma albert webson shixiang shane gu zhuyun dai mirac suzgun xinyun chen aakanksha chowdhery sharan narang gaurav mishra adam yu vincent zhao yanping huang andrew dai hongkun yu slav petrov ed h chi jeff dean jacob devlin adam robert denny zhou quoc v le jason wei 1 flanul2_docflanul2 google ai released repository googleresearcht55xblobmaindocsmodelsmdflanul2checkpoints hyung chung le hou shayne longpre barret zoph yi tay william fedus eric li xuezhi wang mostafa dehghani siddhartha brahma albert webson shixiang shane gu zhuyun dai mirac suzgun xinyun chen aakanksha chowdhery sharan narang gaurav mishra adam yu vincent zhao yanping huang andrew dai hongkun yu slav petrov ed h chi jeff dean jacob devlin adam robert denny zhou quoc v le jason wei 1 _docflaubert cnrs released paper flaubert unsupervised language model pretraining 191205372 hang le loic vial jibril frej vincent segonne maximin coavoux benjamin lecouteux alexandre allauzen benoit crabbe laurent besacier didier schwab 1 _docflava facebook ai released paper flava foundational language vision alignment 211204482 amanpreet singh ronghang hu vedanuj goswami guillaume couairon wojciech galuba marcus rohrbach douwe kiela 1 _docfnet google research released paper fnet mixing token fourier 210503824 james leethorp joshua ainslie ilya eckstein santiago ontanon 1 _docfocalnet microsoft research released paper focal modulation 220311926 jianwei yang chunyuan li xiyang dai lu yuan jianfeng gao 1 funnel _docfunnel cmugoogle brain released paper funneltransformer filtering sequential redundancy efficient language 200603236 zihang dai guokun lai yiming yang quoc v le 1 _docgit microsoft research released paper git generative imagetotext transformer vision 220514100 jianfeng wang zhengyuan yang xiaowei hu linjie li kevin lin zhe gan zicheng liu ce liu lijuan wang 1 _docglpn kaist released paper globallocal path network monocular depth estimation vertical 220107436 doyeon kim woonghyun ga pyungwhan ahn donggyu joo sehwan chun junmo kim 1 _docopenaigpt openai released paper improving language understanding generative  alec radford karthik narasimhan tim salimans ilya sutskever 1 gpt _docgpt_neo eleutherai released repository  sid black stella biderman leo gao phil wang connor leahy 1 gpt _docgpt_neox eleutherai released paper gptneox20b opensource autoregressive language 220406745 sid black stella biderman eric hallahan quentin anthony leo gao laurence golding horace connor leahy kyle mcdonell jason phang michael pieler usvsn sai prashanth shivanshu purohit laria reynolds jonathan tow ben wang samuel weinbach 1 gpt neox _docgpt_neox_japanese abeja released shinya otani takayoshi makabe anuj arora kyo hattori 1 gpt2_docgpt2 openai released paper language model unsupervised multitask  alec radford jeffrey wu rewon child david luan dario amodei ilya sutskever 1 _docgptj eleutherai released repository  ben wang aran komatsuzaki 1 gptsw3_docgptsw3 aisweden released paper lesson learned gptsw3 building first largescale generative language model 2022pdf2022lrec1376pdf ariel ekgren amaru cuba gyllensten evangelia gogoulou alice heiman severine verlinden joey ohman fredrik carlsson magnus sahlgren 1 _docgpt_bigcode bigcode released paper santacoder dont reach 230103988 loubna ben allal raymond li denis kocetkov chenghao mou christopher akiki carlos munoz ferrandis niklas muennighoff mayank mishra alex gu manan dey logesh kumar umapathi carolyn jane anderson yangtian zi joel lamy poirier hailey schoelkopf sergey troshin dmitry abulkhanov manuel romero michael lappert francesco de toni bernardo garcia del rio qian liu shamik bose urvashi bhattacharyya terry yue zhuo ian yu paulo villegas marco zocca sourab mangrulkar david lansky huu nguyen danish contractor luis villa jia li dzmitry bahdanau yacine jernite sean hughes daniel fried arjun guha harm de vries leandro von werra 1 _docgptsanjapanese released repository  toshiyuki sakamototanreinama 1 _docgraphormer microsoft released paper transformer really perform bad graph 210605234 chengxuan ying tianle cai shengjie luo shuxin zheng guolin ke di yanming shen tieyan liu 1 _docgroupvit ucsd nvidia released paper groupvit semantic segmentation emerges text 220211094 jiarui xu shalini de mello sifei liu wonmin byeon thomas breuel jan kautz xiaolong wang 1 _dochubert facebook released paper hubert selfsupervised speech representation learning masked prediction hidden 210607447 weining hsu benjamin bolte yaohung hubert tsai kushal lakhotia ruslan salakhutdinov abdelrahman mohamed 1 _docibert berkeley released paper ibert integeronly bert 210101321 sehoon kim amir gholami zhewei yao michael w mahoney kurt keutzer 1 _docimagegpt openai released paper generative pretraining  mark chen alec radford rewon child jeffrey wu heewoo jun david luan ilya sutskever 1 _docinformer beihang university uc berkeley rutgers university sedd company released paper informer beyond efficient transformer long sequence timeseries 201207436 haoyi zhou shanghang zhang jieqi peng shuai zhang jianxin li hui xiong wancai zhang 1 _docjukebox openai released paper jukebox generative model 200500341pdf prafulla dhariwal heewoo jun christine payne jong wook kim alec radford ilya sutskever 1 _doclayoutlm microsoft research asia released paper layoutlm pretraining text layout document image 191213318 yiheng xu minghao li lei cui shaohan huang furu wei ming zhou 1 layoutlmv2_doclayoutlmv2 microsoft research asia released paper layoutlmv2 multimodal pretraining visuallyrich document 201214740 yang xu yiheng xu tengchao lv lei cui furu wei guoxin wang yijuan lu dinei florencio cha zhang wanxiang che min zhang lidong zhou 1 layoutlmv3_doclayoutlmv3 microsoft research asia released paper layoutlmv3 pretraining document ai unified text image 220408387 yupan huang tengchao lv lei cui yutong lu furu wei 1 _doclayoutxlm microsoft research asia released paper layoutxlm multimodal pretraining multilingual visuallyrich document 210408836 yiheng xu tengchao lv lei cui guoxin wang yijuan lu dinei florencio cha zhang furu wei 1 _docled allenai released paper longformer longdocument 200405150 iz beltagy matthew e peter arman cohan 1 _doclevit meta ai released paper levit vision transformer convnets clothing faster 210401136 ben graham alaaeldin elnouby hugo touvron pierre stock armand joulin herve jegou matthijs douze 1 _doclilt south china university technology released paper lilt simple yet effective languageindependent layout transformer structured document 220213669 jiapeng wang lianwen jin kai ding 1 _docllama fair team meta ai released paper llama open efficient foundation language 230213971 hugo touvron thibaut lavril gautier izacard xavier martinet marieanne lachaux timothee lacroix baptiste roziere naman goyal eric hambro faisal azhar aurelien rodriguez armand joulin edouard grave guillaume lample 1 _doclongformer allenai released paper longformer longdocument 200405150 iz beltagy matthew e peter arman cohan 1 longt5_doclongt5 google ai released paper longt5 efficient texttotext transformer long 211207916 mandy guo joshua ainslie david uthus santiago ontanon jianmo ni yunhsuan sung yinfei yang 1 _docluke studio ousia released paper luke deep contextualized entity representation entityaware 201001057 ikuya yamada akari asai hiroyuki shindo hideaki takeda yuji matsumoto 1 _doclxmert unc chapel hill released paper lxmert learning crossmodality encoder representation transformer opendomain question 190807490 hao tan mohit bansal 1 _docmctct facebook released paper pseudolabeling massively multilingual speech 211100161 loren lugosch tatiana likhomanenko gabriel synnaeve ronan collobert 1 m2m100_docm2m_100 facebook released paper beyond englishcentric multilingual machine 201011125 angela fan shruti bhosale holger schwenk zhiyi ahmed elkishky siddharth goyal mandeep baines onur celebi guillaume wenzek vishrav chaudhary naman goyal tom birch vitaliy liptchinsky sergey edunov edouard grave michael auli armand joulin 1 _docmarian machine translation model trained using  data jorg tiedemann marian  developed microsoft translator team 1 _docmarkuplm microsoft research asia released paper markuplm pretraining text markup language visuallyrich document 211008518 junlong li yiheng xu lei cui furu wei 1 mask2_docmask2former fair uiuc released paper maskedattention mask transformer universal image 211201527 bowen cheng ishan misra alexander g schwing alexander kirillov rohit girdhar 1 _docmaskformer meta uiuc released paper perpixel classification need semantic 210706278 bowen cheng alexander g schwing alexander kirillov 1 _docmatcha google ai released paper matcha enhancing visual language pretraining math reasoning chart 221209662 fangyu liu francesco piccinno syrine krichene chenxi pang kenton lee mandar joshi yasemin altun nigel collier julian martin eisenschlos 1 _docmbart facebook released paper multilingual denoising pretraining neural machine 200108210 yinhan liu jiatao gu naman goyal xian li sergey edunov marjan ghazvininejad mike lewis luke zettlemoyer 1 mbart50_docmbart facebook released paper multilingual translation extensible multilingual pretraining 200800401 yuqing tang chau tran xian li pengjen chen naman goyal vishrav chaudhary jiatao gu angela fan 1 _docmega facebook released paper mega moving average equipped gated 220910655 xuezhe chunting zhou xiang kong junxian liangke gui graham neubig jonathan may luke zettlemoyer 1 _docmegatronbert nvidia released paper megatronlm training multibillion parameter language model using model 190908053 mohammad shoeybi mostofa patwary raul puri patrick legresley jared casper bryan catanzaro 1 megatrongpt2_docmegatron_gpt2 nvidia released paper megatronlm training multibillion parameter language model using model 190908053 mohammad shoeybi mostofa patwary raul puri patrick legresley jared casper bryan catanzaro 1 _docmgpstr alibaba research released paper multigranularity prediction scene text 220903592 peng wang cheng da cong yao 1 _docmluke studio ousia released paper mluke power entity representation multilingual pretrained language 211008151 ryokan ri ikuya yamada yoshimasa tsuruoka 1 _docmobilebert cmugoogle brain released paper mobilebert compact taskagnostic bert resourcelimited 200402984 zhiqing sun hongkun yu xiaodan song renjie liu yiming yang denny zhou 1 mobilenetv1_docmobilenet_v1 google inc released paper mobilenets efficient convolutional neural network mobile vision 170404861 andrew g howard menglong zhu bo chen dmitry kalenichenko weijun wang tobias weyand marco andreetto hartwig adam 1 mobilenetv2_docmobilenet_v2 google inc released paper mobilenetv2 inverted residual linear 180104381 mark sandler andrew howard menglong zhu andrey zhmoginov liangchieh chen 1 _docmobilevit apple released paper mobilevit lightweight generalpurpose mobilefriendly vision 211002178 sachin mehta mohammad rastegari 1 _docmpnet microsoft research released paper mpnet masked permuted pretraining language 200409297 kaitao song xu tan tao qin jianfeng lu tieyan liu 1 mt5_docmt5 google ai released paper mt5 massively multilingual pretrained texttotext 201011934 linting xue noah constant adam robert mihir kale ramus alrfou aditya siddhant aditya barua colin raffel 1 _docmvp ruc ai box released paper mvp multitask supervised pretraining natural language 220612131 tianyi tang junyi li wayne xin zhao jirong wen 1 _docnat shi lab released paper neighborhood attention 220407143 ali hassani steven walton jiachen li shen li humphrey shi 1 _docnezha huawei noah ark lab released paper nezha neural contextualized representation chinese language 190900204 junqiu wei xiaozhe ren xiaoguang li wenyong huang yi liao yasheng wang jiashu lin xin jiang xiao chen qun liu 1 _docnllb meta released paper language left behind scaling humancentered machine 220704672 nllb team 1 _docnllbmoe meta released paper language left behind scaling humancentered machine 220704672 nllb team 1 _docnystromformer university wisconsin madison released paper nystromformer nystrombased algorithm approximating 210203902 yunyang xiong zhanpeng zeng rudrasis chakraborty mingxing tan glenn fung yin li vikas singh 1 _doconeformer shi lab released paper oneformer one transformer rule universal image 221106220 jitesh jain jiachen li mangtik chiu ali hassani nikita orlov humphrey shi 1 _docopenllama  released  1 _docopt meta ai released paper opt open pretrained transformer language 220501068 susan zhang stephen roller naman goyal mikel artetxe moya chen shuohui chen et al 1 _docowlvit google ai released paper simple openvocabulary object detection vision 220506230 matthias minderer alexey gritsenko austin stone maxim neumann dirk weissenborn alexey dosovitskiy aravindh mahendran anurag arnab mostafa dehghani zhuoran shen xiao wang xiaohua zhai thomas kipf neil houlsby 1 _docpegasus google released paper pegasus pretraining extracted gapsentences abstractive 191208777 jingqing zhang yao zhao mohammad saleh peter j liu 1 _docpegasus_x google released paper investigating efficiently extending transformer long input 220804347 jason phang yao zhao peter j liu 1 perceiver _docperceiver deepmind released paper perceiver io general architecture structured input 210714795 andrew jaegle sebastian borgeaud jeanbaptiste alayrac carl doersch catalin ionescu david ding skanda koppula daniel zoran andrew brock evan shelhamer olivier henaff matthew botvinick andrew zisserman oriol vinyals joao carreira 1 _docphobert vinai research released paper phobert pretrained language model 2020findingsemnlp92 dat quoc nguyen anh tuan nguyen 1 pix2_docpix2struct google released paper pix2struct screenshot parsing pretraining visual language 221003347 kenton lee mandar joshi iulia turc hexiang hu fangyu liu julian eisenschlos urvashi khandelwal peter shaw mingwei chang kristina toutanova 1 _docplbart ucla nlp released paper unified pretraining program understanding 210306333 wasi uddin ahmad saikat chakraborty baishakhi ray kaiwei chang 1 _docpoolformer sea ai lab released paper metaformer actually need 211111418 yu weihao luo mi zhou pan si chenyang zhou yichen wang xinchao feng jiashi yan shuicheng 1 _docprophetnet microsoft research released paper prophetnet predicting future ngram sequencetosequence 200104063 yu yan weizhen qi yeyun gong dayiheng liu nan duan jiusheng chen ruofei zhang ming zhou 1 _docqdqbert nvidia released paper integer quantization deep learning inference principle empirical 200409602 hao wu patrick judd xiaojie zhang mikhail isaev paulius micikevicius 1 _docrag facebook released paper retrievalaugmented generation knowledgeintensive nlp 200511401 patrick lewis ethan perez aleksandara piktus fabio petroni vladimir karpukhin naman goyal heinrich kuttler mike lewis wentau yih tim rocktaschel sebastian riedel douwe kiela 1 _docrealmhtml google research released paper realm retrievalaugmented language model 200208909 kelvin guu kenton lee zora tung panupong pasupat mingwei chang 1 _docreformer google research released paper reformer efficient 200104451 nikita kitaev ukasz kaiser anselm levskaya 1 _docregnet meta platform released paper designing network design 200313678 ilija radosavovic raj prateek kosaraju ross girshick kaiming piotr dollar 1 _docrembert google research released paper rethinking embedding coupling pretrained language 201012821 hyung chung thibault fevry henry tsai johnson sebastian ruder 1 _docresnet microsoft research released paper deep residual learning image 151203385 kaiming xiangyu zhang shaoqing ren jian sun 1 _docroberta facebook released together paper roberta robustly optimized bert pretraining 190711692 yinhan liu myle ott naman goyal jingfei du mandar joshi danqi chen omer levy mike lewis luke zettlemoyer veselin stoyanov 1 _docrobertaprelayernorm facebook released paper fairseq fast extensible toolkit sequence 190401038 myle ott sergey edunov alexei baevski angela fan sam gross nathan ng david grangier michael auli 1 _docroc_bert wechatai released paper rocbert robust chinese bert multimodal contrastive 2022acllong65pdf huisu weiweishi xiaoyushen xiaozhou tuoji jiaruifang jiezhou 1 _docroformer zhuiyitechnology released together paper roformer enhanced transformer rotary position 210409864 jianlin su yu lu shengfeng pan bo wen yunfeng liu 1 _docrwkv bo peng released  bo peng 1 _docsegformer nvidia released paper segformer simple efficient design semantic segmentation 210515203 enze xie wenhai wang zhiding yu anima anandkumar jose alvarez ping luo 1 segment _docsam meta ai released paper segment 230402643v1pdf alexander kirillov eric mintun nikhila ravi hanzi mao chloe rolland laura gustafson tete xiao spencer whitehead alex berg wanyen lo piotr dollar ross girshick 1 _docsew asapp released paper performanceefficiency tradeoff unsupervised pretraining speech 210906870 felix wu kwangyoun kim jing pan kyu han kilian q weinberger yoav artzi 1 _docsew_d asapp released paper performanceefficiency tradeoff unsupervised pretraining speech 210906870 felix wu kwangyoun kim jing pan kyu han kilian q weinberger yoav artzi 1 speecht5_docspeecht5 microsoft research released paper speecht5 unifiedmodal encoderdecoder pretraining spoken language 211007205 junyi ao rui wang long zhou chengyi wang shuo ren yu wu shujie liu tom ko qing li yu zhang zhihua wei yao qian jinyu li furu wei 1 _docspeech_to_text facebook released together paper fairseq s2t fast speechtotext modeling 201005171 changhan wang yun tang xutai anne wu dmytro okhonko juan pino 1 speechtotexttransformer2_docspeech_to_text_2 facebook released together paper largescale self semisupervised learning speech 210406678 changhan wang anne wu juan pino alexei baevski michael auli alexis conneau 1 _docsplinter tel aviv university released together paper fewshot question answering pretraining span 210100438 ori ram yuval kirstain jonathan berant amir globerson omer levy 1 _docsqueezebert berkeley released paper squeezebert computer vision teach nlp efficient neural 200611316 forrest n iandola albert e shaw ravi krishna kurt w keutzer 1 _docswiftformer mbzuai released paper swiftformer efficient additive attention transformerbased realtime mobile vision 230315446 abdelrahman shaker muhammad maaz hanoona rasheed salman khan minghsuan yang fahad shahbaz khan 1 swin _docswin microsoft released paper swin transformer hierarchical vision transformer using shifted 210314030 ze liu yutong lin yue cao han hu yixuan wei zheng zhang stephen lin baining guo 1 swin transformer v2_docswinv2 microsoft released paper swin transformer v2 scaling capacity 211109883 ze liu han hu yutong lin zhuliang yao zhenda xie yixuan wei jia ning yue cao zheng zhang li dong furu wei baining guo 1 swin2_docswin2sr university wurzburg released paper swin2sr swinv2 transformer compressed image superresolution 220911345 marcos v conde uijin choi maxime burchi radu timofte 1 _docswitch_transformers google released paper switch transformer scaling trillion parameter model simple efficient 210103961 william fedus barret zoph noam shazeer 1 t5_doct5 google ai released paper exploring limit transfer learning unified texttotext 191010683 colin raffel noam shazeer adam robert katherine lee sharan narang michael matena yanqi zhou wei li peter j liu 1 t5v11_doct5v11 google ai released repository _checkpointsmdt511 colin raffel noam shazeer adam robert katherine lee sharan narang michael matena yanqi zhou wei li peter j liu 1 table _doctabletransformer microsoft research released paper pubtables1m towards comprehensive table extraction unstructured 211000061 brandon smock rohith pesala robin abraham 1 _doctapas google ai released paper tapa weakly supervised table parsing via 200402349 jonathan herzig pawe krzysztof nowak thomas muller francesco piccinno julian martin eisenschlos 1 _doctapex microsoft research released paper tapex table pretraining via learning neural sql 210707653 qian liu bei chen jiaqi guo morteza ziyadi zeqi lin weizhu chen jianguang lou 1 time series _doctime_series_transformer huggingface 1 _doctimesformer facebook released paper spacetime attention need video 210205095 gedas bertasius heng wang lorenzo torresani 1 trajectory _doctrajectory_transformers university california berkeley released paper offline reinforcement learning one big sequence modeling 210602039 michael janner qiyang li sergey levine 1 _doctransfoxl googlecmu released paper transformerxl attentive language model beyond fixedlength 190102860 zihang dai zhilin yang yiming yang jaime carbonell quoc v le ruslan salakhutdinov 1 _doctrocr microsoft released together paper trocr transformerbased optical character recognition pretrained 210910282 minghao li tengchao lv lei cui yijuan lu dinei florencio cha zhang zhoujun li furu wei 1 _doctvlt unc chapel hill released paper tvlt textless visionlanguage 220914156 zineng tang jaemin cho yixin nie mohit bansal 1 ul2_docul2 google research released paper unifying language learning 220505131v1 yi tay mostafa dehghani vinh q tran xavier garcia dara bahri tal schuster huaixiu steven zheng neil houlsby donald metzler 1 _docunispeech microsoft research released paper unispeech unified speech representation learning labeled unlabeled 210107597 chengyi wang yu wu yao qian kenichi kumatani shujie liu furu wei michael zeng xuedong huang 1 _docunispeechsat microsoft research released paper unispeechsat universal speech representation learning speaker aware 211005752 sanyuan chen yu wu chengyi wang zhengyang chen zhuo chen shujie liu jian wu yao qian furu wei jinyu li xiangzhan yu 1 _docupernet peking university released paper unified perceptual parsing scene 180710221 tete xiao yingcheng liu bolei zhou yuning jiang jian sun 1 _docvan tsinghua university nankai university released paper visual attention 220209741 menghao guo chengze lu zhengning liu mingming cheng shimin hu 1 _docvideomae multimedia computing group nanjing university released paper videomae masked autoencoders dataefficient learner selfsupervised video 220312602 zhan tong yibing song jue wang limin wang 1 _docvilt naver ai labkakao enterprisekakao brain released paper vilt visionandlanguage transformer without convolution region 210203334 wonjae kim bokyung son ildoo kim 1 vision transformer _docvit google ai released paper image worth 16x16 word transformer image recognition 201011929 alexey dosovitskiy lucas beyer alexander kolesnikov dirk weissenborn xiaohua zhai thomas unterthiner mostafa dehghani matthias minderer georg heigold sylvain gelly jakob uszkoreit neil houlsby 1 _docvisual_bert ucla nlp released paper visualbert simple performant baseline vision 190803557 liunian harold li mark yatskar da yin chojui hsieh kaiwei chang 1 vit _docvit_hybrid google ai released paper image worth 16x16 word transformer image recognition 201011929 alexey dosovitskiy lucas beyer alexander kolesnikov dirk weissenborn xiaohua zhai thomas unterthiner mostafa dehghani matthias minderer georg heigold sylvain gelly jakob uszkoreit neil houlsby 1 _docvit_mae meta ai released paper masked autoencoders scalable vision 211106377 kaiming xinlei chen saining xie yanghao li piotr dollar ross girshick 1 _docvit_msn meta ai released paper masked siamese network labelefficient 220407141 mahmoud assran mathilde caron ishan misra piotr bojanowski florian bordes pascal vincent armand joulin michael rabbat nicolas ballas 1 wav2vec2_docwav2vec2 facebook ai released paper wav2vec 20 framework selfsupervised learning speech 200611477 alexei baevski henry zhou abdelrahman mohamed michael auli 1 wav2vec2_docwav2vec2conformer facebook ai released paper fairseq s2t fast speechtotext modeling 201005171 changhan wang yun tang xutai anne wu sravya popuri dmytro okhonko juan pino 1 wav2vec2_docwav2vec2_phoneme facebook ai released paper simple effective zeroshot crosslingual phoneme 210911680 qiantong xu alexei baevski michael auli 1 _docwavlm microsoft research released paper wavlm largescale selfsupervised pretraining full stack speech 211013900 sanyuan chen chengyi wang zhengyang chen yu wu shujie liu zhuo chen jinyu li naoyuki kanda takuya yoshioka xiong xiao jian wu long zhou shuo ren yanmin qian yao qian jian wu michael zeng furu wei 1 _docwhisper openai released paper robust speech recognition via largescale weak  alec radford jong wook kim tao xu greg brockman christine mcleavey ilya sutskever 1 _docxclip microsoft research released paper expanding languageimage pretrained model general video 220802816 bolin ni houwen peng minghao chen songyang zhang gaofeng meng jianlong fu shiming xiang haibin ling 1 _docxmod meta ai released paper lifting curse multilinguality pretraining modular 1018653v12022naaclmain255 jonas pfeiffer naman goyal xi lin xian li james cross sebastian riedel mikel artetxe 1 _docxglm facebook ai released paper fewshot learning multilingual language 211210668 xi victoria lin todor mihaylov mikel artetxe tianlu wang shuohui chen daniel simig myle ott naman goyal shruti bhosale jingfei du ramakanth pasunuru sam shleifer punit singh koura vishrav chaudhary brian ohoro jeff wang luke zettlemoyer zornitsa kozareva mona diab veselin stoyanov xian li 1 _docxlm facebook released together paper crosslingual language model 190107291 guillaume lample alexis conneau 1 _docxlmprophetnet microsoft research released paper prophetnet predicting future ngram sequencetosequence 200104063 yu yan weizhen qi yeyun gong dayiheng liu nan duan jiusheng chen ruofei zhang ming zhou 1 _docxlmroberta facebook ai released together paper unsupervised crosslingual representation learning 191102116 alexis conneau kartikay khandelwal naman goyal vishrav chaudhary guillaume wenzek francisco guzman edouard grave myle ott luke zettlemoyer veselin stoyanov 1 _docxlmrobertaxl facebook ai released together paper largerscale transformer multilingual masked language 210500572 naman goyal jingfei du myle ott giri anantharaman alexis conneau 1 _docxlmv meta ai released paper xlmv overcoming vocabulary bottleneck multilingual masked language 230110472 davis liang hilum gonen yuning mao rui hou naman goyal marjan ghazvininejad luke zettlemoyer madian khabsa 1 _docxlnet googlecmu released paper xlnet generalized autoregressive pretraining language 190608237 zhilin yang zihang dai yiming yang jaime carbonell ruslan salakhutdinov quoc v le 1 _docxls_r facebook ai released paper xlsr selfsupervised crosslingual speech representation learning 211109296 arun babu changhan wang andros tjandra kushal lakhotia qiantong xu naman goyal kritika singh patrick von platen yatharth saraf juan pino alexei baevski alexis conneau michael auli 1 xlsrwav2vec2_docxlsr_wav2vec2 facebook ai released paper unsupervised crosslingual representation learning speech 200613979 alexis conneau alexei baevski ronan collobert abdelrahman mohamed michael auli 1 _docyolos huazhong university science technology released paper look one sequence rethinking transformer vision object 210600666 yuxin fang bencheng liao xinggang wang jiemin fang jiyang qi rui wu jianwei niu wenyu liu 1 _docyoso university wisconsin madison released paper sample almost linear cost selfattention via bernoulli 211109714 zhanpeng zeng yunyang xiong sathya n ravi shailesh acharya glenn fung vikas singh 1 want contribute new model added detailed guide template guide process adding new model find templatestemplates folder repository sure check contributing guidelinescontributingmd contact maintainer open issue collect feedback starting pr check model ha implementation flax pytorch tensorflow ha associated tokenizer backed tokenizers library refer  implementation tested several datasets see example script match performance original implementation find detail performance example section  learn section description  full api documentation tutorial task _summary task supported transformer preprocessing  using tokenizer class prepare data model training  using model provided transformer pytorchtensorflow training loop trainer api quick tour finetuningusage  example script finetuning model wide range task model sharing _sharing upload share finetuned model community  migrate transformer pytorchtransformers pytorchpretrainedbert citation 2020emnlpdemos6 cite transformer library bibtex inproceedingswolfetal2020transformers title transformer stateoftheart natural language processing author thomas wolf lysandre debut victor sanh julien chaumond clement delangue anthony moi pierric cistac tim rault remi louf morgan funtowicz joe davison sam shleifer patrick von platen clara yacine jernite julien plu canwen xu teven le scao sylvain gugger mariama drame quentin lhoest alexander rush booktitle proceeding 2020 conference empirical method natural language processing system demonstration month oct year 2020 address online publisher association computational linguistics url 2020emnlpdemos6 page 3845'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_http[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11c9b01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7aaeeaac",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 76: expected str instance, float found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/49/v6sf5vy165dghytk4qv6jfhc0000gn/T/ipykernel_1846/778395869.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpython_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'Python'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cleaned_readme_contents'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhtml_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'HTML'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cleaned_readme_contents'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mall_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cleaned_readme_contents'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 76: expected str instance, float found"
     ]
    }
   ],
   "source": [
    "python_words = ' '.join(train[train.language=='Python']['cleaned_readme_contents'])\n",
    "html_words = ' '.join(train[train.language=='HTML']['cleaned_readme_contents'])\n",
    "all_words = ' '.join(train['cleaned_readme_contents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abda44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccd211c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = nltk.sentiment.SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d8fda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['compound_sentiment'] = train['cleaned_readme_contents'].apply(\n",
    "    lambda x: sia.polarity_scores(x)['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a337e4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fddf409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is the mean and median values of sentiment score different for ham vs spam?\n",
    "sentiments = train.groupby('language')['compound_sentiment'].mean()\n",
    "sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba5fcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments.plot.barh()\n",
    "plt.title('Python Has Slightly Higher Average Sentiment Score', size=16)\n",
    "plt.xlabel('Sentiment Score', size=16)\n",
    "plt.ylabel('Programming Language', size=16)\n",
    "plt.xticks(size=14)\n",
    "plt.yticks(size=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408339b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.barh(data=sentiments, hue='language')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa1fa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visual3(train):\n",
    "    '''\n",
    "    This will display the mean average sentiment score for python and html repos\n",
    "    '''\n",
    "    # create sentiment analyzer object\n",
    "    sia = nltk.sentiment.SentimentIntensityAnalyzer()\n",
    "    # get sentiment scores for every repo in the training dataset\n",
    "    train['compound_sentiment'] = train['cleaned_readme_contents'].apply(\n",
    "        lambda x: sia.polarity_scores(x)['compound'])\n",
    "    # get the average sentiment score for each language\n",
    "    sentiments = train.groupby('language')['compound_sentiment'].mean()\n",
    "    # display a horizontal bar plot of the avg sentiment scores\n",
    "    sentiments.plot.barh()\n",
    "    # add title\n",
    "    plt.title('Python Has Slightly Higher Average Sentiment Score', size=16)\n",
    "    # add axis labels\n",
    "    plt.xlabel('Average Sentiment Score', size=16)\n",
    "    plt.ylabel('Programming Language', size=16)\n",
    "    # resize tick labels\n",
    "    plt.xticks(size=14)\n",
    "    plt.yticks(size=14)\n",
    "    # show plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f611605a",
   "metadata": {},
   "outputs": [],
   "source": [
    "visual3(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2a638a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m========== REJECT THE NULL HYPOTHESIS! ==========\u001b[0m\n",
      "\u001b[35mP-Value:\u001b[0m 0.00000064\n",
      "\u001b[35mChi-Squared-Value:\u001b[0m 24.79972519\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "observed = pd.crosstab(train.language,\n",
    "                       train.cleaned_readme_contents.str.contains('srchttps_link'))\n",
    "chi2, p, _, hypothetical = stats.chi2_contingency(observed)\n",
    "\n",
    "if p < alpha:\n",
    "    print('\\033[32m========== REJECT THE NULL HYPOTHESIS! ==========\\033[0m')\n",
    "    print(f'\\033[35mP-Value:\\033[0m {p:.8f}')\n",
    "    print(f'\\033[35mChi-Squared-Value:\\033[0m {chi2:.8f}')\n",
    "else:\n",
    "    print('\\033[31m========== ACCEPT THE NULL HYPOTHESIS! ==========\\033[0m')\n",
    "    print(f'\\033[35mP-Value:\\033[0m {p:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18e62578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>cleaned_readme_contents</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HTML</th>\n",
       "      <td>125</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Python</th>\n",
       "      <td>136</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "cleaned_readme_contents  False  True\n",
       "language                            \n",
       "HTML                       125    15\n",
       "Python                     136    73"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(train.language,train.cleaned_readme_contents.str.contains('srchttps_link'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "688e35da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[104.6991404,  35.3008596],\n",
       "       [156.3008596,  52.6991404]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothetical"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
