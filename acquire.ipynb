{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0d04d4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import acquire as a\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d891132e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = a.scrape_github_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576fc3c9",
   "metadata": {},
   "source": [
    "#### By adding repo names to the REPOS area of the acquire.py file, in the format 'gocodeup/codeup-setup-script' (no spaces) they will be added to the list of repo readme contents that will be scraped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc555ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'repo': 'gocodeup/codeup-setup-script',\n",
       "  'language': 'Shell',\n",
       "  'readme_contents': '# Codeup Setup Script\\n\\nSetup script for Codeup students\\' laptops to install all of the tools we will\\nneed for the java course. We will install the following:\\n\\n- [xcode](https://developer.apple.com/xcode/features/): command line tools for\\n  macs\\n- [brew](http://brew.sh/): package manager for macs\\n- [java](https://en.wikipedia.org/wiki/Java_(programming_language))\\n- [tomcat](http://tomcat.apache.org/): the java webserver\\n- [maven](https://maven.apache.org/): a java dependency and build management tool\\n- [mysql](https://www.mysql.com/): the database we\\'ll use for the class\\n- [node js](https://nodejs.org/en/): a JavaScript runtime outside the browser\\n- [npm](https://www.npmjs.com/): a package manager for JavaScript\\n- [intellij](https://www.jetbrains.com/idea/): a Java IDE\\n\\nIn addition, we will:\\n\\n- setup ssh keys for the student\\'s laptop and guide them through the process of\\n  linking their ssh key to their Github account.\\n- Setup a global gitignore file and set the default commit editor to `nano`\\n  (only if these are not already set)\\n\\n## For Students\\n\\nCopy and paste the following in your terminal:\\n\\n```\\nbash -c \"$(curl -sS https://raw.githubusercontent.com/gocodeup/codeup-setup-script/master/install.sh)\"\\n```\\n\\n## Note for Instructors\\n\\nIf students already have an `id_rsa` ssh key generated, the script will *not*\\ntry to generate a new ones, and you will need to walk them through the process\\nof adding their existing key to Github.\\n\\nThe following should do the trick if they already have a ssh key pair, but it\\'s\\nnot wired up to Github.\\n\\n```bash\\npbcopy < ~/.ssh/id_rsa.pub\\nopen https://github.com/settings/ssh\\n```\\n'},\n",
       " {'repo': 'gocodeup/movies-application',\n",
       "  'language': 'JavaScript',\n",
       "  'readme_contents': '# Movies Application\\n\\nFor this project, we will be building a single page movie application (SPA). It\\nwill allow users to add, edit, and delete movies, as well as rate them. We will\\nbe using [`json-server`](https://github.com/typicode/json-server) to mock a\\ndatabase and our backend, so that we can just worry about the front end and AJAX\\nrequests.\\n\\nThe webpack dev server is configured to watch for changes both in the javascript\\nsource, as well as the `public` directory. Whenever changes are detected, the\\npage will be reloaded. It will also proxy any requests that start with `/api` to\\nlocalhost:3000, which is where json-server is configured run.\\n\\n`json-server` is configured to have a delay of 1.2 seconds, so you can see what\\nyour application might actually look like, instead of serving instantaneous\\nreponses. You can modify this behavior by changing (or removing) the number\\nafter the `-d` flag inside of the npm `dev` script.\\n\\n## Setup\\n\\n1. Fork this repository to your own github account or your github organization.\\n\\n1. Clone your fork locally into your computer.\\n\\n1. Run `npm install`\\n\\n1. Run `npm run build`\\n\\n1. Run `npm run dev` and visit\\n   [http://localhost:1313/](http://localhost:1313/) in your browser. Open up\\n   the console and inspect the output.\\n\\n## Development\\n\\nIn general, you should have the development web server (`npm run dev`) running\\nwhile you are working on the project. You should view your project through\\nhttp://localhost:1313, **not** from IntelliJ\\'s web server, or by dragging the\\nfile(s) into chrome. As you make changes to your source files, all you need to\\ndo is save the file, and the website will be live reloaded.\\n\\nTake a look at the `src/index.js` file to get started. You will notice it has\\nexamples of importing and requiring separate javascript files. Regardless of\\nwhich you choose to use, you should pick one and use it throughout your code\\nbase, don\\'t mix and match the two.\\n\\nThe file `src/api.js` also contains an example api request. You can\\nreference this to get started building out the parts of your application that\\ninteract with the api.\\n\\nThe `db.json` file contains your \"database\". You can edit this file directly to\\nmake changes to your data, and this file will be updated if you make api\\nrequests that modify the data.\\n\\nThe server will serve files from the `public` directory, meaning any files\\noutside of `public` will not be visible. This means if you have any frontend\\nassets (e.g. bootstrap, or images) they will need to be in the `public`\\ndirectory.\\n\\n## Specification\\n\\nYour application should:\\n\\nOn page load:\\n\\n- Display a \"loading...\" message\\n- Make an ajax request to get a listing of all the movies\\n- When the initial ajax request comes back, remove the \"loading...\" message\\n  and replace it with HTML generated from the json response your code\\n  receives\\n\\nAllow users to add new movies\\n\\n- Create a form for adding a new movie that has fields for the movie\\'s title\\n  and rating\\n- When the form is submitted, the page should **not** reload / refresh,\\n  instead, your javascript should make a POST request to `/api/movies` with the\\n  information the user put into the form\\n\\nAllow users to edit existing movies\\n\\n- Give users the option to edit an existing movie\\n- A form should be pre-populated with the selected movie\\'s details\\n- Like creating a movie, this should not involve any page reloads, instead\\n  your javascript code should make an ajax request when the form is\\n  submitted.\\n\\nDelete movies\\n\\n- Each movie should have a \"delete\" button\\n- When this button is clicked, your javascript should send a `DELETE` request\\n\\n### Bonuses\\n\\n- Add a `disabled` attribute to buttons while their corresponding ajax request\\n  is still pending.\\n- Show a loading animation instead of just text that says \"loading...\"\\n- Use modals for the creating and editing movie forms\\n- Add a `genre` property to every movie\\n- Allow users to sort the movies by rating, title, or genre (if you have it)\\n- Allow users to search through the movies by rating, title, or genre (if you\\n  have it)\\n\\n## Helpful Hints\\n\\n- The id property of every movie should not be edited by hand. The purpose of\\n  this property is to uniquely identify that particular movie. That is, if we\\n  want to delete or modify an existing movie, we can specify what movie we want\\n  to change by referencing it\\'s id. When a new movie is created (i.e.  when you\\n  send a `POST` request to `/api/movies` with a title and a rating), the server\\n  will respond with the movie object that was created, including a generated id.\\n- Take a look at the other branches in this repository, as they have\\n  configuration/setup for common scenarios, such as including bootstrap in your\\n  application.\\n'},\n",
       " {'repo': 'torvalds/linux',\n",
       "  'language': 'C',\n",
       "  'readme_contents': 'Linux kernel\\n============\\n\\nThere are several guides for kernel developers and users. These guides can\\nbe rendered in a number of formats, like HTML and PDF. Please read\\nDocumentation/admin-guide/README.rst first.\\n\\nIn order to build the documentation, use ``make htmldocs`` or\\n``make pdfdocs``.  The formatted documentation can also be read online at:\\n\\n    https://www.kernel.org/doc/html/latest/\\n\\nThere are various text files in the Documentation/ subdirectory,\\nseveral of them using the Restructured Text markup notation.\\n\\nPlease read the Documentation/process/changes.rst file, as it contains the\\nrequirements for building and running the kernel, and information about\\nthe problems which may result by upgrading your kernel.\\n'},\n",
       " {'repo': 'Unstructured-IO/unstructured',\n",
       "  'language': 'HTML',\n",
       "  'readme_contents': '<h3 align=\"center\">\\n  <img\\n    src=\"https://raw.githubusercontent.com/Unstructured-IO/unstructured/main/img/unstructured_logo.png\"\\n    height=\"200\"\\n  >\\n</h3>\\n\\n<div align=\"center\">\\n\\n  <a href=\"https://github.com/Unstructured-IO/unstructured/blob/main/LICENSE.md\">![https://pypi.python.org/pypi/unstructured/](https://img.shields.io/pypi/l/unstructured.svg)</a>\\n  <a href=\"https://pypi.python.org/pypi/unstructured/\">![https://pypi.python.org/pypi/unstructured/](https://img.shields.io/pypi/pyversions/unstructured.svg)</a>\\n  <a href=\"https://GitHub.com/unstructured-io/unstructured/graphs/contributors\">![https://GitHub.com/unstructured-io/unstructured.js/graphs/contributors](https://img.shields.io/github/contributors/unstructured-io/unstructured)</a>\\n  <a href=\"https://github.com/Unstructured-IO/unstructured/blob/main/CODE_OF_CONDUCT.md\">![code_of_conduct.md](https://img.shields.io/badge/Contributor%20Covenant-2.1-4baaaa.svg) </a>\\n  <a href=\"https://GitHub.com/unstructured-io/unstructured/releases\">![https://GitHub.com/unstructured-io/unstructured.js/releases](https://img.shields.io/github/release/unstructured-io/unstructured)</a>\\n  <a href=\"https://pypi.python.org/pypi/unstructured/\">![https://github.com/Naereen/badges/](https://badgen.net/badge/Open%20Source%20%3F/Yes%21/blue?icon=github)</a>\\n  [![Downloads](https://static.pepy.tech/badge/unstructured)](https://pepy.tech/project/unstructured)\\n  [![Downloads](https://static.pepy.tech/badge/unstructured/month)](https://pepy.tech/project/unstructured)\\n\\n</div>\\n\\n<div>\\n  <p align=\"center\">\\n  <a\\n  href=\"https://join.slack.com/t/unstructuredw-kbe4326/shared_invite/zt-1nlh1ot5d-dfY7zCRlhFboZrIWLA4Qgw\">\\n    <img src=\"https://img.shields.io/badge/JOIN US ON SLACK-4A154B?style=for-the-badge&logo=slack&logoColor=white\" />\\n  </a>\\n  <a href=\"https://www.linkedin.com/company/unstructuredio/\">\\n    <img src=\"https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white\" />\\n  </a>\\n</div>\\n<h2 align=\"center\">\\n  <p>Announcement!!!</p>\\n</h2>\\n<div align=\"center\">\\n  <p>We\\'re excited to announce the public release of the unstructured.io hosted API! Now you can leverage Unstructured with a simple API call to render clean text in JSON format out of your images, documents, powerpoints, and more.</p>\\n\\n<p>Checkout the <a href=\"https://github.com/Unstructured-IO/unstructured-api#--\">readme</a> here to get started making API calls. You‚Äôll also find instructions there about how to host your own version of the API. Unstructured data just got easier!\\nWe\\'d love to hear your feedback, let us know how it goes in our <a\\n  href=\"https://join.slack.com/t/unstructuredw-kbe4326/shared_invite/zt-1nlh1ot5d-dfY7zCRlhFboZrIWLA4Qgw\">\\n   community slack</a>. And stay tuned for improvements to both quality and performance over the coming months!\\n<p><img src=\"easy.gif\"></p></p>\\n</div>\\n\\n<h3 align=\"center\">\\n  <p>Open-Source Pre-Processing Tools for Unstructured Data</p>\\n</h3>\\n\\nThe `unstructured` library provides open-source components for pre-processing text documents\\nsuch as **PDFs**, **HTML** and **Word** Documents. These components are packaged as *bricks* üß±, which provide\\nusers the building blocks they need to build pipelines targeted at the documents they care\\nabout. Bricks in the library fall into three categories:\\n\\n- :jigsaw: ***Partitioning bricks*** that break raw documents down into standard, structured\\n  elements.\\n- :broom: ***Cleaning bricks*** that remove unwanted text from documents, such as boilerplate and\\n  sentence\\n  fragments.\\n- :performing_arts: ***Staging bricks*** that format data for downstream tasks, such as ML inference\\n  and data labeling.\\n\\n<br></br>\\n\\n## :eight_pointed_black_star: Quick Start\\n\\nUse the following instructions to get up and running with `unstructured` and test your\\ninstallation. NOTE: We do not currently support python 3.11, please use an older version.\\n\\n- Install the Python SDK with `pip install \"unstructured[local-inference]\"`\\n\\t\\t- If you do not need to process PDFs or images, you can run `pip install unstructured`\\n- Install the following system dependencies if they are not already available on your system.\\n  Depending on what document types you\\'re parsing, you may not need all of these.\\n    - `libmagic-dev` (filetype detection)\\n    - `poppler-utils` (images and PDFs)\\n    - `tesseract-ocr` (images and PDFs)\\n    - `libreoffice` (MS Office docs)\\n- If you are parsing PDFs, run the following to install the `detectron2` model, which\\n  `unstructured` uses for layout detection:\\n    - `pip install tensorboard>=2.12.2`\\n    - `pip install \"detectron2@git+https://github.com/facebookresearch/detectron2.git@e2ce8dc#egg=detectron2\"`\\n\\nAt this point, you should be able to run the following code:\\n\\n```python\\nfrom unstructured.partition.auto import partition\\n\\nelements = partition(filename=\"example-docs/fake-email.eml\")\\nprint(\"\\\\n\\\\n\".join([str(el) for el in elements]))\\n```\\n\\nAnd if you installed with `local-inference`, you should be able to run this as well:\\n\\n```python\\nfrom unstructured.partition.auto import partition\\n\\nelements = partition(\"example-docs/layout-parser-paper.pdf\")\\nprint(\"\\\\n\\\\n\".join([str(el) for el in elements]))\\n```\\n\\n## :dizzy: Instructions for using the docker image\\n\\nThe following instructions are intended to help you get up and running using Docker to interact with `unstructured`.\\nSee [here](https://docs.docker.com/get-docker/) if you don\\'t already have docker installed on your machine.\\n\\nNOTE: we build multi-platform images to support both x86_64 and Apple silicon hardware. `docker pull` should download the corresponding image for your architecture, but you can specify with `--platform` (e.g. `--platform linux/amd64`) if needed.\\n\\nWe build Docker images for all pushes to `main`. We tag each image with the corresponding short commit hash (e.g. `fbc7a69`) and the application version (e.g. `0.5.5-dev1`). We also tag the most recent image with `latest`. To leverage this, `docker pull` from our image repository.\\n\\n```bash\\ndocker pull quay.io/unstructured-io/unstructured:latest\\n```\\n\\nOnce pulled, you can create a container from this image and shell to it.\\n\\n```bash\\n# create the container\\ndocker run -dt --name unstructured quay.io/unstructured-io/unstructured:latest\\n\\n# this will drop you into a bash shell where the Docker image is running\\ndocker exec -it unstructured bash\\n```\\n\\nYou can also build your own Docker image.\\n\\nIf you only plan on parsing one type of data you can speed up building the image by commenting out some\\nof the packages/requirements necessary for other data types. See Dockerfile to know which lines are necessary\\nfor your use case.\\n\\n```bash\\nmake docker-build\\n\\n# this will drop you into a bash shell where the Docker image is running\\nmake docker-start-bash\\n```\\n\\nOnce in the running container, you can try things out directly in Python interpreter\\'s interactive mode.\\n```bash\\n# this will drop you into a python console so you can run the below partition functions\\npython3\\n\\n>>> from unstructured.partition.pdf import partition_pdf\\n>>> elements = partition_pdf(filename=\"example-docs/layout-parser-paper-fast.pdf\")\\n\\n>>> from unstructured.partition.text import partition_text\\n>>> elements = partition_text(filename=\"example-docs/fake-text.txt\")\\n```\\n\\n\\n## :coffee: Installation Instructions for Local Development\\n\\nThe following instructions are intended to help you get up and running with `unstructured`\\nlocally if you are planning to contribute to the project.\\n\\n* Using `pyenv` to manage virtualenv\\'s is recommended but not necessary\\n\\t* Mac install instructions. See [here](https://github.com/Unstructured-IO/community#mac--homebrew) for more detailed instructions.\\n\\t\\t* `brew install pyenv-virtualenv`\\n\\t  * `pyenv install 3.8.15`\\n  * Linux instructions are available [here](https://github.com/Unstructured-IO/community#linux).\\n\\n* Create a virtualenv to work in and activate it, e.g. for one named `unstructured`:\\n\\n\\t`pyenv  virtualenv 3.8.15 unstructured` <br />\\n\\t`pyenv activate unstructured`\\n\\n* Run `make install`\\n\\n* Optional:\\n  * To install models and dependencies for processing images and PDFs locally, run `make install-local-inference`.\\n  * For processing image files, `tesseract` is required. See [here](https://tesseract-ocr.github.io/tessdoc/Installation.html) for installation instructions.\\n  * For processing PDF files, `tesseract` and `poppler` are required. The [pdf2image docs](https://pdf2image.readthedocs.io/en/latest/installation.html) have instructions on installing `poppler` across various platforms.\\n\\nAdditionally, if you\\'re planning to contribute to `unstructured`, we provide you an optional `pre-commit` configuration\\nfile to ensure your code matches the formatting and linting standards used in `unstructured`.\\nIf you\\'d prefer not having code changes auto-tidied before every commit, you can use  `make check` to see\\nwhether any linting or formatting changes should be applied, and `make tidy` to apply them.\\n\\nIf using the optional `pre-commit`, you\\'ll just need to install the hooks with `pre-commit install` since the\\n`pre-commit` package is installed as part of `make install` mentioned above. Finally, if you decided to use `pre-commit`\\nyou can also uninstall the hooks with `pre-commit uninstall`.\\n\\n## :clap: Quick Tour\\n\\nYou can run this [Colab notebook](https://colab.research.google.com/drive/1U8VCjY2-x8c6y5TYMbSFtQGlQVFHCVIW) to run the examples below.\\n\\nThe following examples show how to get started with the `unstructured` library.\\nYou can parse **TXT**, **HTML**, **PDF**, **EML**, **MSG**, **RTF**, **EPUB**, **DOC**, **DOCX**,\\n**ODT**, **PPT**, **PPTX**, **JPG**,\\nand **PNG** documents with one line of code!\\n<br></br>\\nSee our [documentation page](https://unstructured-io.github.io/unstructured) for a full description\\nof the features in the library.\\n\\n### Document Parsing\\n\\nThe easiest way to parse a document in unstructured is to use the `partition` brick. If you\\nuse `partition` brick, `unstructured` will detect the file type and route it to the appropriate\\nfile-specific partitioning brick.\\nIf you are using the `partition` brick, you may need to install additional parameters via `pip install unstructured[local-inference]`. Ensure you first install `libmagic` using the\\ninstructions outlined [here](https://unstructured-io.github.io/unstructured/installing.html#filetype-detection)\\n`partition` will always apply the default arguments. If you need\\nadvanced features, use a document-specific brick. The `partition` brick currently works for\\n`.txt`, `.doc`, `.docx`, `.ppt`, `.pptx`, `.jpg`, `.png`, `.eml`, `.msg`, `.html`, and `.pdf` documents.\\n\\n```python\\nfrom unstructured.partition.auto import partition\\n\\nelements = partition(\"example-docs/layout-parser-paper.pdf\")\\n```\\n\\nRun `print(\"\\\\n\\\\n\".join([str(el) for el in elements]))` to get a string representation of the\\noutput, which looks like:\\n\\n```\\n\\nLayoutParser : A UniÔ¨Åed Toolkit for Deep Learning Based Document Image Analysis\\n\\nZejiang Shen 1 ( (cid:0) ), Ruochen Zhang 2 , Melissa Dell 3 , Benjamin Charles Germain Lee 4 , Jacob Carlson 3 , and\\nWeining Li 5\\n\\nAbstract. Recent advances in document image analysis (DIA) have been primarily driven by the application of neural\\nnetworks. Ideally, research outcomes could be easily deployed in production and extended for further investigation.\\nHowever, various factors like loosely organized codebases and sophisticated model conÔ¨Ågurations complicate the easy\\nreuse of im- portant innovations by a wide audience. Though there have been on-going eÔ¨Äorts to improve reusability and\\nsimplify deep learning (DL) model development in disciplines like natural language processing and computer vision, none\\nof them are optimized for challenges in the domain of DIA. This represents a major gap in the existing toolkit, as DIA\\nis central to academic research across a wide range of disciplines in the social sciences and humanities. This paper\\nintroduces LayoutParser , an open-source library for streamlining the usage of DL in DIA research and applica- tions.\\nThe core LayoutParser library comes with a set of simple and intuitive interfaces for applying and customizing DL models\\nfor layout de- tection, character recognition, and many other document processing tasks. To promote extensibility,\\nLayoutParser also incorporates a community platform for sharing both pre-trained models and full document digiti- zation\\npipelines. We demonstrate that LayoutParser is helpful for both lightweight and large-scale digitization pipelines in\\nreal-word use cases. The library is publicly available at https://layout-parser.github.io\\n\\nKeywords: Document Image Analysis ¬∑ Deep Learning ¬∑ Layout Analysis ¬∑ Character Recognition ¬∑ Open Source library ¬∑\\nToolkit.\\n\\nIntroduction\\n\\nDeep Learning(DL)-based approaches are the state-of-the-art for a wide range of document image analysis (DIA) tasks\\nincluding document image classiÔ¨Åcation [11,\\n```\\n\\n### HTML Parsing\\n\\nYou can parse an HTML document using the following workflow:\\n\\n```python\\nfrom unstructured.partition.html import partition_html\\n\\nelements = partition_html(\"example-docs/example-10k.html\")\\nprint(\"\\\\n\\\\n\".join([str(el) for el in elements[:5]]))\\n```\\n\\nThe print statement will show the following text:\\n```\\nUNITED STATES\\n\\nSECURITIES AND EXCHANGE COMMISSION\\n\\nWashington, D.C. 20549\\n\\nFORM 10-K\\n\\nANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\\n```\\n\\nAnd `elements` will be a list of elements in the HTML document, similar to the following:\\n\\n```python\\n[<unstructured.documents.elements.Title at 0x169cbe820>,\\n <unstructured.documents.elements.NarrativeText at 0x169cbe8e0>,\\n <unstructured.documents.elements.NarrativeText at 0x169cbe3a0>]\\n```\\n\\n### PDF Parsing\\n\\nYou can use the following workflow to parse PDF documents.\\n\\n```python\\nfrom unstructured.partition.pdf import partition_pdf\\n\\nelements = partition_pdf(\"example-docs/layout-parser-paper.pdf\")\\n```\\n\\nThe output will look the same as the example from the document parsing section above.\\n\\n\\n### E-mail Parsing\\n\\nThe `partition_email` function within `unstructured` is helpful for parsing `.eml` files. Common\\ne-mail clients such as Microsoft Outlook and Gmail support exporting e-mails as `.eml` files.\\n`partition_email` accepts filenames, file-like object, and raw text as input. The following\\nthree snippets for parsing `.eml` files are equivalent:\\n\\n```python\\nfrom unstructured.partition.email import partition_email\\n\\nelements = partition_email(filename=\"example-docs/fake-email.eml\")\\n\\nwith open(\"example-docs/fake-email.eml\", \"r\") as f:\\n  elements = partition_email(file=f)\\n\\nwith open(\"example-docs/fake-email.eml\", \"r\") as f:\\n  text = f.read()\\nelements = partition_email(text=text)\\n```\\n\\nThe `elements` output will look like the following:\\n\\n```python\\n[<unstructured.documents.html.HTMLNarrativeText at 0x13ab14370>,\\n<unstructured.documents.html.HTMLTitle at 0x106877970>,\\n<unstructured.documents.html.HTMLListItem at 0x1068776a0>,\\n<unstructured.documents.html.HTMLListItem at 0x13fe4b0a0>]\\n```\\n\\nRun `print(\"\\\\n\\\\n\".join([str(el) for el in elements]))` to get a string representation of the\\noutput, which looks like:\\n\\n```python\\nThis is a test email to use for unit tests.\\n\\nImportant points:\\n\\nRoses are red\\n\\nViolets are blue\\n```\\n\\n### Text Document Parsing\\n\\nThe `partition_text` function within `unstructured` can be used to parse simple\\ntext files into elements.\\n\\n`partition_text` accepts filenames, file-like object, and raw text as input. The following three snippets are for parsing text files:\\n\\n```python\\nfrom unstructured.partition.text import partition_text\\n\\nelements = partition_text(filename=\"example-docs/fake-text.txt\")\\n\\nwith open(\"example-docs/fake-text.txt\", \"r\") as f:\\n  elements = partition_text(file=f)\\n\\nwith open(\"example-docs/fake-text.txt\", \"r\") as f:\\n  text = f.read()\\nelements = partition_text(text=text)\\n```\\n\\nThe `elements` output will look like the following:\\n\\n```python\\n[<unstructured.documents.html.HTMLNarrativeText at 0x13ab14370>,\\n<unstructured.documents.html.HTMLTitle at 0x106877970>,\\n<unstructured.documents.html.HTMLListItem at 0x1068776a0>,\\n<unstructured.documents.html.HTMLListItem at 0x13fe4b0a0>]\\n```\\n\\nRun `print(\"\\\\n\\\\n\".join([str(el) for el in elements]))` to get a string representation of the\\noutput, which looks like:\\n\\n```python\\nThis is a test document to use for unit tests.\\n\\nImportant points:\\n\\nHamburgers are delicious\\n\\nDogs are the best\\n\\nI love fuzzy blankets\\n```\\n\\n\\n## :guardsman: Security Policy\\n\\nSee our [security policy](https://github.com/Unstructured-IO/unstructured/security/policy) for\\ninformation on how to report security vulnerabilities.\\n\\n## :books: Learn more\\n\\n| Section | Description |\\n|-|-|\\n| [Company Website](https://unstructured.io) | Unstructured.io product and company info |\\n| [Documentation](https://unstructured-io.github.io/unstructured) | Full API documentation |\\n| [Batch Processing](Ingest.md) | Ingesting batches of documents through Unstructured |\\n'},\n",
       " {'repo': 'akoumjian/datefinder',\n",
       "  'language': 'HTML',\n",
       "  'readme_contents': 'datefinder - extract dates from text\\n====================================\\n\\n.. image:: https://github.com/akoumjian/datefinder/actions/workflows/python-package.yml/badge.svg\\n    :target: https://github.com/akoumjian/datefinder\\n    :alt: Build Status\\n\\n.. image:: https://img.shields.io/pypi/dm/datefinder.svg\\n    :target: https://pypi.python.org/pypi/datefinder/\\n    :alt: pypi downloads per day\\n\\n.. image:: https://img.shields.io/pypi/v/datefinder.svg\\n    :target: https://pypi.python.org/pypi/datefinder\\n    :alt: pypi version\\n\\n\\nA python module for locating dates inside text. Use this package to extract all sorts \\nof date like strings from a document and turn them into datetime objects.\\n\\nThis module finds the likely datetime strings and then uses  \\n`dateutil` to convert to the datetime object.\\n\\n\\nInstallation\\n------------\\n\\n**With pip**\\n\\n.. code-block:: sh\\n\\n    pip install datefinder\\n\\n**Note:  I do not publish the version on conda forge and cannot verify its integrity.**\\n\\nHow to Use\\n----------\\n\\n\\n.. code-block:: python\\n\\n    In [1]: string_with_dates = \"\"\"\\n       ...: ...\\n       ...: entries are due by January 4th, 2017 at 8:00pm\\n       ...: ...\\n       ...: created 01/15/2005 by ACME Inc. and associates.\\n       ...: ...\\n       ...: \"\"\"\\n\\n    In [2]: import datefinder\\n\\n    In [3]: matches = datefinder.find_dates(string_with_dates)\\n\\n    In [4]: for match in matches:\\n       ...:     print match\\n       ...:\\n    2017-01-04 20:00:00\\n    2005-01-15 00:00:00\\n\\n\\nDemo\\n----\\n\\n-  üéûÔ∏è `Video demo`_ by Calmcode.io. :star: \\n\\n.. _Video demo: https://calmcode.io/shorts/datefinder.py.html\\n\\n'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ffc76c",
   "metadata": {},
   "source": [
    "#### Our first step should be to scrape a list of repo names. On github the repo names have spaces, so the spaces will also need to be removed before they can be added to the REPOS list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1f242ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp projects using python\n",
    "python_url = 'https://github.com/topics/nlp?l=python'\n",
    "# nlp projects using html\n",
    "html_url = 'https://github.com/topics/nlp?l=html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c727743",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://github.com/topics/nlp?l=python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c3ac7ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7851e3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8b2cc00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b4086ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/huggingface/transformers'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grab one project repo name from the soup\n",
    "soup.find_all('a', class_=\"text-bold wb-break-word\")[0]['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "82acffd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(soup.find_all('a', class_=\"text-bold wb-break-word\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ecc92827",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_url_list = [item['href'] for item in \n",
    "                   soup.find_all('a', class_=\"text-bold wb-break-word\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "55c40735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/huggingface/transformers',\n",
       " '/apachecn/ailearning',\n",
       " '/google-research/bert',\n",
       " '/hankcs/HanLP',\n",
       " '/explosion/spaCy',\n",
       " '/RasaHQ/rasa',\n",
       " '/huggingface/datasets',\n",
       " '/mindsdb/mindsdb',\n",
       " '/RaRe-Technologies/gensim',\n",
       " '/flairNLP/flair',\n",
       " '/microsoft/unilm',\n",
       " '/nltk/nltk',\n",
       " '/PaddlePaddle/PaddleHub',\n",
       " '/allenai/allennlp',\n",
       " '/chiphuyen/stanford-tensorflow-tutorials',\n",
       " '/PaddlePaddle/PaddleNLP',\n",
       " '/deepset-ai/haystack',\n",
       " '/sloria/TextBlob',\n",
       " '/ymcui/Chinese-BERT-wwm',\n",
       " '/ymcui/Chinese-LLaMA-Alpaca']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_url_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c9d9f1",
   "metadata": {},
   "source": [
    "#### There is 20, now to figure out how to get more results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557e302d",
   "metadata": {},
   "source": [
    "<form class=\"ajax-pagination-form js-ajax-pagination\" data-turbo=\"false\" action=\"https://github.com/topics/nlp?l=python\" accept-charset=\"UTF-8\" method=\"get\">\n",
    "    <input name=\"page\" type=\"hidden\" value=\"2\">\n",
    "    <button type=\"submit\" class=\"ajax-pagination-btn btn btn-outline color-border-default f6 mt-0 width-full\" data-disable-with=\"Loading more‚Ä¶\">\n",
    "      Load more‚Ä¶\n",
    "    </button>\n",
    "</form>\n",
    "<input name=\"page\" type=\"hidden\" value=\"2\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
